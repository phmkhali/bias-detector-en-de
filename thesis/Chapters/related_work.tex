\chapter{Related Work}

This section outlines key findings of related work on gender bias in MT, with a focus on the English-German language pair to build the theoretical knowledge base. The research aims are to (1) define the core concept of gender bias in MT, (2) establish the relevance of the topic, (3) identify the research gap, and (4) justify technical design choices. To support this, I examine datasets, model types, and tools used in previous studies.

For the literature review I combined incremental and conceptual literature review methods, where each source led to the identification of the next. Based on this progression, I identified key concepts and used them to organize and interpret the literature, aligning with a conceptual approach. The structure followed the qualitative Information Systems framework by \citet{schryenWritingQualitativeLiterature2015} and was further informed by \citet{shresthaExploringGenderBiases2022} and \citet{savoldiDecadeGenderBias2025}, who both conducted systematic reviews on gender bias in ML and MT respectively. 

\section{Literature Search Process}

\subsection{Search Sources and Tools}
Sources were primarily searched on \href{https://scholar.google.com/}{Google Scholar} and \href{https://www.perplexity.ai/}{Perplexity}, which served as an additional search engine. Prompts and outputs from Perplexity have been saved and are included in the appendix. To organize and manage the collected sources, \href{https://www.zotero.org/}{Zotero} was used throughout the process.

\subsection{Literature Review Framing}

To answer the four research aims, I have defined the key concepts in \autoref{tab:key-concepts}. Key search terms consisted of \textit{gender bias}, \textit{machine translation}, \textit{AI}, \textit{machine learning}, \textit{German}, \textit{stereotypes}, and \textit{detection}. The focus was on literature published between 2019 and 2025 to maintain relevance and currency, while foundational and definitional works from earlier periods were selectively included. The initial search for the term \textit{gender bias in machine translation} returned over 18,000 results. Through my iterative selection process, this was narrowed down to 34 core sources.

\renewcommand{\arraystretch}{1.3}
\begin{table}[ht!]
\centering
\begin{tabularx}{\textwidth}{lX}
\toprule
\textbf{Key Concept} & \textbf{Description} \\
\midrule
Stereotypes and Biases in Society & Introduces the social foundations of bias by explaining how stereotypes form, persist, and shape expectations about gender roles. Necessary to understand why certain translation outputs may reflect or reinforce societal gender norms. \\

Machine and Algorithmic Bias & Explains how social biases can enter ML systems through data, design choices, or feedback mechanisms. Sets the groundwork for understanding how gender bias can emerge in translation models used in this thesis. \\

Gender Bias in English-German Translation & Focuses on the specific challenges of translating between English and German, where the lack of grammatical gender in English and its necessity in German can cause biased outputs. Defines the types of gender bias relevant to the classification task in this thesis. \\

Bias Detection Frameworks & Reviews existing methods for identifying gender bias in language data and ML outputs. Helps justify the choice of a classification approach for detecting bias in translations. \\

\bottomrule
\end{tabularx}
\caption{Key concepts relevant to this thesis}
\label{tab:key-concepts}
\end{table}

\subsection{Citation Tracking}
Backward citation searching involved reviewing references cited by selected papers, prioritizing frequently cited and foundational works relevant to gender bias in MT. Forward citation searching used Google Scholar's "cited by" function to identify newer research citing those key papers. Filtering with specific terms (e.g., \textit{German} and \textit{machine translation}) was applied during forward search to maintain focus. In addition to the main review process, supplementary sources were included as needed throughout the writing phase. These consist of contextual references, statistics, or secondary citations that support specific points but were not part of the core conceptual or methodological framework.

\subsection{Selection Criteria and Screening Process}
Titles and abstracts were manually screened to select relevant studies. Inclusion criteria required sources to specifically address gender bias in MT, provide examples or discussions of gender-related errors, or explain the significance of gender bias in this context. Exclusion criteria filtered out studies focusing on general NLP bias without a direct link to MT, non-gender biases without clear gender connection, and highly technical papers lacking contribution to the general understanding of gender bias. Full texts were reviewed after initial screening to confirm relevance and extract insights. Redundant sources not providing new perspectives aligned with the thesis goals were excluded.

\section{Foundations of Gender Bias in Natural Language Processing}

\subsection{Foundational studies}
The existence of gender bias in MT is well-documented. First mentions of this issue date back to over a decade ago, having been recognized by a paper by \citeauthor{schiebingerScientificResearchMust2014} in 2014. Since then, there has been a general increase in research papers focusing on this topic, especially between 2019 and 2023 \citep{savoldiDecadeGenderBias2025}.

\citet{pratesAssessingGenderBias2019} conducted a large-scale quantitative study using Google Translate, translating sentences such as "He/She is an engineer" from twelve gender-neutral languages into English. The study revealed a significant overrepresentation of male pronouns, particularly in STEM-related occupations. This skew was not attributable to actual gender distributions in the labor market, suggesting that the bias stemmed from imbalances in the system’s training data. The paper received widespread media coverage, which was followed by a policy change by \citeauthor{googleReducingGenderBias2018} to present both feminine and masculine official translations for ambiguous queries \citep{googleReducingGenderBias2018}, acknowledging that their model inadvertently replicated gender biases (refer to \autoref{fig:gt_prates_example}). 

\citet{stanovskyEvaluatingGenderBias2019} introduced WinoMT, a challenge set designed to evaluate gender bias in translations of English sentences into eight target languages with grammatical gender. The study showed that both commercial and academic MT systems failed to preserve correct gender in non-stereotypical roles, while performing better on stereotypical ones. In line with the findings of \citeauthor{pratesAssessingGenderBias2019}, the study demonstrated a systematic preference for traditional gender roles in translations. This pattern is further supported by \citeauthor{choMeasuringGenderBias2019} (\citeyear{choMeasuringGenderBias2019}), who showed that occupational terms exhibit higher levels of gender bias across systems compared to other semantic categories. 

These foundational studies not only confirm the existence of systematic gender bias in MT outputs, but also lay the groundwork for subsequent research that builds upon their findings to develop more robust evaluation methods and mitigation strategies.

\subsection{Human-Centered Studies}
In addition to analyzing MT outputs directly, some studies have assessed the real-world implications of gender bias by measuring its impact on human effort. \citet{savoldiWhatHarmQuantifying2024} conducted a human-centered evaluation in which approximately 90 participants were tasked with post-editing MT outputs to ensure gender-accurate translations.

The study employed behavioral metrics such as time to edit and the number of edits, measured through human-targeted error rate, to quantify the effort required. The results showed that post-editing feminine translations required nearly twice as much time and four times the number of editing operations compared to masculine counterparts. Consequently this effort gap also translates into higher economic costs, suggesting a measurable quality-of-service disadvantage that disproportionately affects women. \citeauthor{savoldiWhatHarmQuantifying2024} concluded that current automatic bias metrics do not sufficiently capture these human-centered disparities, emphasizing the need for evaluation methods that reflect real user experience.

\subsection{Types of Gender Bias}
% what is bias
% what is gender bias - basics
% types of biases, what counts as it
% statistics and prove how it affects people



\section{Sources and Manifestations of Bias}
\subsection{Causes of Gender Bias}
% ullmann
% stanczak
% smacchia

%data ias (coverage. social)
%algorithmic bias

\subsection{Perpetuation of existing biases}


\subsection{Implications}
% how it manifests
% how it affects it in this specific case
% refer to bias because of society
% how context affects it

\section{Linguistic Challenges in English-German Translation}

\subsection{Grammatical Gender}
Although both English and German originate from the Indo-European language family \citep{baldiEnglishIndoEuropeanLanguage2008}, they have different characteristcs. English does not assign grammatical gender to nouns. The article "the" is used universally, independent of what it refers to. On the contrary, German assigns one of three grammatical gendered articles to nouns: "der" (m), "die" (f) and "das" (n). The form or ending of a noun may also change depending on its grammatical gender. While English has a few gendered word pairs, such as "actor" (m) and "actress" (f), gender distinctions in German apply broadly across the entire noun system. "Der Student" refers to a male student, whereas "die Studentin" refers to a female student. Note that grammatical gender has no connection to societal or biological gender. It is a rule of the language rather than a reflection of identity. For example, the German word Mädchen (girl) is grammatically neuter and takes the article "das". This is not because the referent lacks gender, but because the suffix "-chen" automatically assigns neuter gender. This illustrates that grammatical gender in German follows structural rules, even when they contradict real-world gender associations.

\subsection{Gender-Fair Language}

\subsubsection{The Generic Masculine}  
In both singular and plural contexts, the \textit{generic masculine} refers to the default use of the masculine grammatical gender. It is commonly used in spoken German \citep{lardelliBuildingBridgesDataset2024,schmitzGermanAllProfessors2022}, although research has consistently shown that masculine generics create a male bias in mental representations, leading readers or listeners to think more of male than female examples \citep{sczesnyCanGenderFairLanguage2016}. Similarly, \citet{rescignoGenderBiasMachine2023} observed a predominance of masculine forms in translation outputs (approximately 90\% in Google Translate and 85–88\% in DeepL—for) English–Italian and English–German pairs, even when the original sentences contained relatively few masculine references. These linguistic biases in human language naturally carry over into ML systems. Since most models for NLP are trained on large datasets of human-generated text, they inadvertently learn and reproduce the same sociolinguistic biases present in the data \citep{choMeasuringGenderBias2019}.

\subsubsection{All students are male}
The English sentence "The students are studying" does not indicate the genders of the individuals involved. There are various ways to translate that sentence into German. The plural forms of the gendered term "student" would be "die Studenten" (multiple male students) and "die Studentinnen" (multiple female students). The problem arises when there is a mix of male and female students or when the genders are unknown. 
Using the common generic masculine, the sentence translates to \textit{die Studenten lernen}, with the male term referring to a (potentially mixed-gender) group. As \citet{schmitzGermanAllProfessors2022} pointed out, if the female form is not explicitly mentioned, the phrase is understood as all students are male.

The rise of the gender-fair language (GFL) debate was a response to this structural asymmetry. It refers to the use of language that treats all genders equally and aims to reduce stereotyping and discrimination \citep{sczesnyCanGenderFairLanguage2016}. 
There are four main approaches to GFL in German identified by \citet{lardelliBuildingBridgesDataset2024}. I will not discuss two of them further because they are less common and face greater hurdles for broader public and professional acceptance.

\begin{itemize}
    \item \textbf{Gender-neutral rewording:}  
    This uses neutral terms instead of gendered nouns, e.g., \textit{die Studierenden lernen}. A challenge for this version is that neutral alternatives do not exist for every noun and cannot be consistently applied.

    \item \textbf{Gender-inclusive characters:}  
    This combines masculine and feminine forms using a character like \textit{*}, \textit{:}, or \textit{\_}, e.g., \textit{die Student*innen lernen}. This method is consistent but may interrupt reading flow and lacks standardization.
\end{itemize}

\noindent Another approach not mentioned by \citeauthor{lardelliBuildingBridgesDataset2024} is to simply name both forms (pair form), e.g. \textit{die Studenten und Studentinnen lernen}. It is currently the most used GFL form in German \citep{waldendorfWordsChangeIncrease2024}, briefly surpassing the star and colon characters as seen in \autoref{fig:gfl_types_frequency}.

\begin{figure}
	\centering
		\includegraphics[width=1\textwidth]{gfl_types_frequency.png}
	\caption{Frequency of different types of gender-inclusive language. Source: \citet{waldendorfWordsChangeIncrease2024}.}
	\label{fig:gfl_types_frequency}
\end{figure}


\subsection{English-German Studies}
This language pair in particular is sparsely analysed in academia. I found x papers 

\citet{stanovskyEvaluatingGenderBias2019} conducted one of the earliest systematic evaluations revealed that even when explicit feminine gender information is present in the source text, translation systems often ignore contextual cues and default to masculine interpretations, particularly for professional occupations and roles traditionally associated with men.


German to Multiple Target Languages
Using datasets with explicit grammatical gender cues, studies found persistent gender bias in MT outputs to languages such as French, Italian, Spanish, Ukrainian, Russian, Arabic, and Hebrew. Despite clear gender markers in German, commercial systems favored masculine forms, revealing systemic bias beyond source language ambiguity. Underrepresentation of females and stereotypical translations were common.


\subsection{Cross-Language Perspectives}
Gender bias in MT is not limited to English and German. Many other language pairs show similar patterns, revealing how bias is shaped by both language and the systems behind it. This section includes a few examples from other languages to show that the issue is not specific to German. While this thesis focuses on the English-German pair, it is important to keep the broader context in mind to avoid a narrow, language-specific perspective.

Some studies looked at \textbf{back-translation from English through gender-neutral languages} like Finnish, Indonesian, and Turkish, then back to English. They found different pronoun patterns depending on the language. This shows why it is important to study many languages to understand gender bias better. Verbs played a big role in how gender was inferred in translations. New metrics, like Adjusted Uncertainty, helped capture these details. Some translation systems showed signs of reducing bias over time \citep{barclayInvestigatingMarkersDrivers2024a}.

When translating \textbf{gender-neutral Korean into English}, MT systems often leaned toward masculine pronouns. This happened because the training data had more male examples. Some systems made technical changes that sometimes favored feminine forms, which suggests bias mitigation is possible. But ideally, translations should stay neutral or balanced \citep{choMeasuringGenderBias2019}. \textbf{Japanese and Chinese} demonstrated exceptionally low percentages of female pronouns in translations, going as low as 0.196\% for Japanese and 1.865\% for Chinese \citep{pratesAssessingGenderBias2019}.

For \textbf{Italian sentences that leave out subjects}, MT systems showed a strong masculine bias for male-dominated jobs. For female-dominated jobs, results were more mixed. These AI biases matched those in human translations, but humans were generally less biased. Also, a “converging bias” appeared, where systems used the same gender repeatedly across the dataset \citep{smacchiaDoesAIReflect2024}.

Even when translating \textbf{between languages that both use grammatical gender}, like German and Spanish, Ukrainian, or Russian, gender bias still shows up. This goes against the assumption that clear grammatical cues would reduce ambiguity and help systems make better choices. Instead, the bias often stays or even gets worse, suggesting that the problem is not just about language structure but also how MT systems learn and generalize from data.


\section{Mitigation Strategies and Current Limitations}    

In respose to the clear issue of gender bias in NLP, different approaches have been tested to mitigate it.

NOTE THAT I AM NOT LOOKING AT MITIGATING IT IN A GENERAL SENSE DUE TO THE SHEER DIFFICULTY OF IT. THE FIRST STEP IS DETECTING SINCE THERE ARE FEW DETECTION SYSTEMS THAT COULD PROVIDE A BASE FIRST. I DONT AIM TO DEBIAS I AM TO RAISE AWARENESS. ZERO SHOT HAS MOSTLY FAILED WITH LLMS SO I WANT TO SEE HOW WELL FINE TUNING PERFORMS.

Technical Approaches:

Fine-tuning models with balanced data 9

Context-aware architectures 11

Gender-neutral translation strategies 9

LLM Potential: While promising, current LLMs like ChatGPT often introduce new biases when explicitly prompted for gender alternatives 9.

Persistent Challenges:

English-centric approaches dominating research 4

Disconnect between translation technologies and operational contexts 4

Difficulty handling non-binary identities

\section{Positioning of My Work}    
% - How your work builds on these findings.
% - What gap you address (binary classifier + demo).
    
%     **Use:** Comparison with prior methods.