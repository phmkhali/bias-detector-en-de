\chapter{Methodology}
This chapter explains the overall approach and structure of the project. It covers how data is handled, how the model is built and trained, and how the demo application is designed.

\section{Goal of the project}
The goal is to build a gender bias detection model for real-world MT scenarios. This includes cases like translating everyday sentences or job descriptions. The focus is to flag bias at the sentence level, so users do not have to find the specific sentences causing bias themselves.

Thus, the model processes each sentence independently. If multiple sentences are inputted, bias is evaluated for each one separately. Context across sentences is not considered, as it does not reflect the intended use case. This approach is also reflected in the design of the training data, where each sentence pair is treated as a standalone instance.

\section{Workflow}
The project begins by selecting and combining datasets from previous work (see \autoref{fig:workflow}). The model building phase then follows, as shown in the purple boxes. It starts with cleaning and preparing the data, followed by extracting features for training. A pre-trained German BERT model is then fine-tuned for the classification task. Its performance is measured using standard evaluation metrics. In the final step, the trained model is integrated into a demo application for user interaction and testing.

\vspace{1cm} 
\begin{figure}[htb]
    \centering
    \scalebox{0.8}{\input{./Bilder/methodology_workflow.tex}}
    \caption{Workflow of the project.}
    \label{fig:workflow}
\end{figure}
\vspace{1cm} 

\section{Dataset Handling}
% thought process for selecting datasets from prior works
% experimental joining and testing of datasets

Since there was no ready-to-use dataset for this task and no prior work that built a similar model, I first had to define: \textbf{(1)} the number of samples required,  and \textbf{(2)} the desired content of my dataset.

\subsection{Number of Samples}
For a binary classification task of detecting gender bias using \texttt{mBERT}, general guidelines suggest between 100 and 5000 labeled samples for fine-tuning \citep{pecherComparingSpecialisedSmall2024}. However, the complex nature of gender bias often requires a larger dataset for robust detection since the number of samples depends mainly on the task type. Multi-class tasks need fewer samples (around 100), while binary tasks can require up to 6,000 or more. \textbf{I will therefore aim to create a dataset with 5000-6000 samples.}

\subsection{Dataset Composition}
Ideally, I wanted to make use of past EN-DE datasets to minimize manual labour. My options were \texttt{\href{https://huggingface.co/datasets/FBK-MT/mGeNTE}{mGeNTE en-de}} \citep{savoldiMGeNTEMultilingualResource2025}, \texttt{\href{https://github.com/g8a9/building-bridges-gender-fair-german-mt}{Building Bridges Dictionary}} \citep{lardelliBuildingBridgesDataset2024}, and \texttt{\href{https://research.google/blog/a-dataset-for-studying-gender-bias-in-translation/}{Translated Wikipedia Biographies}} \citep{stellaDatasetStudyingGender2021}.

\begin{table}[ht!]
    \centering
    \renewcommand{\arraystretch}{1.3}
    \begin{tabularx}{\textwidth}{|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|}
    \hline
    \textbf{Dataset} & \textbf{Description} & \textbf{Content} \\ \hline
    \texttt{mGeNTE en-de} \citep{savoldiMGeNTEMultilingualResource2025} & Multilingual dataset to assess gender bias in MT. & \textasciitilde1,500 gender-ambiguous and gendered English sentences with gender-neutral and gendered German translations. \\ \hline
    \texttt{Building Bridges Dictionary} \citep{lardelliBuildingBridgesDataset2024} & Bilingual dictionary designed to support gender-fair EN-DE translation. & \textasciitilde230 German gender-neutral and gender-inclusive singular and plural sentences with English equivalents. \\ \hline
    \texttt{Translated Wikipedia Biographies} \citep{stellaDatasetStudyingGender2021} & Automatically translated Wikipedia biographies for evaluating gender bias. & \textasciitilde1,500 translated biography sentences with English source text and gender-accurate translated German equivalent. \\ \hline
    \end{tabularx}
    \caption{Overview of available EN-DE datasets based on past works.}
    \label{tab:available_datasets}
\end{table}

While analyzing the \texttt{Translated Wikipedia Biographies} dataset, I found issues that prevented automatic reuse. For example, the \texttt{perceivedGender} column sometimes contained subject names instead of expected labels like Male, Female, or Neutral, which would require manual review. Moreover, the dataset only provided neutral labels (0) since the phrases were correctly gendered. Because my other two datasets are already balanced and include enough neutral examples, I decided to exclude this dataset.

The \texttt{mGeNTE} dataset was suitable for automatic reuse. It includes columns \texttt{SET-G}, \texttt{REF-G}, and \texttt{REF-N}. The \texttt{SET-G} column indicates if the source sentence has a gendered subject. For each entry with a gendered source (\texttt{SET-G}), I add two rows: one with \texttt{REF-G} as the correctly gendered (neutral) label, and one with \texttt{REF-N} as a neutral translation that loses the original gender, making it biased. For source sentences without gendered subjects (\texttt{SET-N}), I apply the same approach but reversed: one row with the neutral source and a correctly gendered translation as biased. This method creates two rows for each original entry, resulting in about 3,000 balanced instances of biased and neutral sentences.

\texttt{Building Bridges Dictionary} did not contain full sentences but rather a gender-fair dictionary of nouns. While this made it a valuable resource for studying gender-fair language, I needed full sentences for my task. To address this, I used prompt engineering with Google Gemini 2.5 Flash to synthetically expand the dataset. The prompt used for generation is included in the appendix. The generated sentences can be found in the code files. I used the nouns from the original dataset to create multiple grammatically correct sentence variations, covering singular, plural, gender-neutral, and gender-inclusive forms. This process resulted in 2,718 sentences.

\subsection{Final Dataset Summary}
The final dataset used for training is a combination of the transformed \texttt{mGeNTE} dataset and the synthetically extended \texttt{Building Bridges Dictionary} dataset. Each source contributes 2,600 sentence pairs, split evenly into 1,300 biased and 1,300 neutral examples, resulting in a balanced dataset of 5,200 entries. The dataset is shuffled before training to prevent source-specific bias. Each entry contains:
\begin{itemize}
    \item an English source sentence (\texttt{english}),
    \item its German translation (\texttt{german}),
    \item and a binary label (\texttt{label}), where \texttt{1} denotes gender bias and \texttt{0} denotes neutrality.
\end{itemize}

\noindent A sample of the dataset is shown below:

\begin{table}[ht!]
\renewcommand{\arraystretch}{1.2}
\setlength{\tabcolsep}{6pt}
\begin{tabularx}{\textwidth}{>{\raggedright\arraybackslash}X >{\raggedright\arraybackslash}X c}
\toprule
\textbf{English} & \textbf{German} & \textbf{Label} \\
\midrule
The laypeople are intelligent. & Die Laiinnen sind intelligent. & 1 \\
The ceramist is responsible. & Der Keramiker ist verantwortlich. & 1 \\
The forest keepers are responsible. & die Forstwart*innen sind verantwortlich. & 0 \\
I am sorry that the Commissioner responsible for agriculture is not here and that she does not have the courage to face us. & Ich bedauere, dass die f체r die Landwirtschaft zust채ndige Kommissarin nicht anwesend ist und nicht den Mut hat, uns gegen체berzutreten. & 0 \\
Mrs Brok, I have no problem whatsoever with this motion. & Ich habe 체berhaupt kein Problem mit diesem Antrag des Kollegiumsmitglieds Brok. & 1 \\
\bottomrule
\end{tabularx}
\caption{Sample entries from the final training dataset.}
\end{table}

\section{Data Pre-processing}

I split the dataset into three parts: training, validation, and test sets. I used stratified sampling for this. That means the label distribution (biased vs. neutral) stays the same across all three sets. This avoids skewed splits. For example, if 30\% of the full dataset is biased, each split will also have 30\% biased samples. This helps the model learn from both classes equally and avoids misleading results in validation or testing.

I did not apply advanced text cleaning such as removing punctuation, lowercasing, or stemming. This is because I use a pretrained BERT tokenizer. These models are trained on raw text and expect natural input. For example, lowercasing "Doctor" to "doctor" could remove useful information if the model has seen one more often than the other. Cleaning might even hurt performance by removing patterns the model understands.

Further data pre-processing was not necessary as I concatenated already clean datasets and manually reviewed them.

\section{Feature extraction}
Feature extraction means turning raw data into a format that the ML model can understand and learn from. To prepare the text for the model, I used a tokenizer that supports sentence pairs. Each input consists of one English sentence and its German translation. The tokenizer encodes them together. This lets the model compare both sides and find patterns related to bias in the translation. For example, if the English says "The nurse is smart" and the German says "Der Pfleger ist klug", the model needs to see both sides to catch the gender mismatch.

I used the tokenizer from \texttt{mBERT}, because it supports both English and German. It maps words and subwords to token IDs that the model understands. Padding and truncation are applied so that all inputs are the same length. I set a fixed maximum length of 128 tokens. Padding adds zeros if the sentence is too short. Truncation cuts off tokens if the sentence is too long. This helps with batch processing and avoids memory issues.

The tokenizer returns token IDs as PyTorch tensors. I also convert the labels (0 or 1) to tensors. This is necessary because the model expects both inputs and labels in tensor format during training.


\section{Model Selection and Training}
% choice of model architecture and reasoning
% training approach overview
\subsection{Hyperparameters}
% experimentation with epochs and other key parameters

\section{Evaluation}
% metrics and evaluation strategy
% validation approach

\section{Demo Application Design}
% concept and structure of the demo app
% how it connects with other components