{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8487e0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kev\\Documents\\GitHub\\bias-detector-en-de\\thesis-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# standard libraries\n",
    "import os\n",
    "import random\n",
    "\n",
    "# data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# torch and dataset utils\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# transformers library\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "# evaluation and data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e222663",
   "metadata": {},
   "source": [
    "# Seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed839ed",
   "metadata": {},
   "source": [
    "calls Python’s random.seed, NumPy’s np.random.seed and PyTorch’s torch.manual_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "471a072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)                  # Python built-in RNG\n",
    "    np.random.seed(seed)               # NumPy RNG\n",
    "    torch.manual_seed(seed)            # PyTorch RNG (CPU)\n",
    "    torch.cuda.manual_seed(seed)       # PyTorch RNG (current GPU)\n",
    "    torch.cuda.manual_seed_all(seed)   # All GPUs (if using multi-GPU)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f6a176",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a751c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>german</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The student representatives are responsible.</td>\n",
       "      <td>die Schülervertreter*innen sind verantwortlich.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I also call upon the Ministers, Heads of State...</td>\n",
       "      <td>Ebenso appelliere ich an die Minister sowie an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The deputies are responsible.</td>\n",
       "      <td>Die Stellvertreterinnen sind verantwortlich.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I do not know whether, as one of the speakers ...</td>\n",
       "      <td>Ich weiß nicht, ob ich wie zuvor gesagt wurde,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The reader is responsible.</td>\n",
       "      <td>Die Leserin ist verantwortlich.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0       The student representatives are responsible.   \n",
       "1  I also call upon the Ministers, Heads of State...   \n",
       "2                      The deputies are responsible.   \n",
       "3  I do not know whether, as one of the speakers ...   \n",
       "4                         The reader is responsible.   \n",
       "\n",
       "                                              german  label  \n",
       "0    die Schülervertreter*innen sind verantwortlich.      0  \n",
       "1  Ebenso appelliere ich an die Minister sowie an...      1  \n",
       "2       Die Stellvertreterinnen sind verantwortlich.      1  \n",
       "3  Ich weiß nicht, ob ich wie zuvor gesagt wurde,...      0  \n",
       "4                    Die Leserin ist verantwortlich.      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/dataset_g.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f54aa9",
   "metadata": {},
   "source": [
    "# Load pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03cf1013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU: NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# print device info\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU: None (using CPU)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bc0e30",
   "metadata": {},
   "source": [
    "## Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ba47b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model name\n",
    "model_path = \"bert-base-multilingual-cased\"\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e99331",
   "metadata": {},
   "source": [
    "## Load Model and Send to Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f279cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model with classification head\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=2,\n",
    "    id2label={0: \"neutral\", 1: \"biased\"},\n",
    "    label2id={\"neutral\": 0, \"biased\": 1}\n",
    ")\n",
    "\n",
    "# move model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb879bcf",
   "metadata": {},
   "source": [
    "# Set trainable parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b4f305",
   "metadata": {},
   "source": [
    "- \"transfer learning\". we leave the base model parameters frozen, only train a classification head that we add on top\n",
    "- might result in rigid model\n",
    "- unfreeze final four layers, keeping computational cost down but keep flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98bc016c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 121152002\n"
     ]
    }
   ],
   "source": [
    "# freeze encoder layers 0 to 7\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"bert.encoder.layer.\"):\n",
    "        layer_num = int(name.split(\".\")[3])\n",
    "        if layer_num <= 7:\n",
    "            param.requires_grad = False\n",
    "\n",
    "# count and print trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable params: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00540c44",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fd93d9",
   "metadata": {},
   "source": [
    "- PyTorch models need input data in a specific format\n",
    "- BiasDataset class turns each row from df into tokenized input tensors for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1d237a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom dataset for bias detection\n",
    "class BiasDataset(Dataset):\n",
    "    # init with dataframe and tokenizer\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    # return number of samples\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # return one encoded sample\n",
    "    def __getitem__(self, idx):\n",
    "        english = self.data.iloc[idx][\"english\"]\n",
    "        german = self.data.iloc[idx][\"german\"]\n",
    "        label = int(self.data.iloc[idx][\"label\"])\n",
    "\n",
    "        # tokenize EN-DE sentence pair\n",
    "        encoded = self.tokenizer(\n",
    "            text=english,\n",
    "            text_pair=german,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=256,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # encoded outputs have extra batch dimension, remove it with squeeze(0) to get plain tensors\n",
    "        item = {key: val.squeeze(0) for key, val in encoded.items()}\n",
    "        # add label tensor to the dict under key 'labels'\n",
    "        item[\"labels\"] = torch.tensor(label)\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bec775",
   "metadata": {},
   "source": [
    "- tokenizer gives tensors with a first size of 1 (a batch)\n",
    "- squeeze(0) removes that first size, making single samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc28df7",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e171490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train (80%) and temp (20%), keeping label distribution same with stratify\n",
    "train_df, temp_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"label\"],\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# split temp into validation (10%) and test (10%) sets, stratified by label\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_df[\"label\"],\n",
    "    random_state=seed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d06d805",
   "metadata": {},
   "source": [
    "## Create Dataset Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f80e26d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, validation and test datasets\n",
    "train_dataset = BiasDataset(train_df, tokenizer)  \n",
    "val_dataset = BiasDataset(val_df, tokenizer)    \n",
    "test_dataset = BiasDataset(test_df, tokenizer)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28148ce4",
   "metadata": {},
   "source": [
    "# Evaluation Metrics Calculation for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c893c9f",
   "metadata": {},
   "source": [
    "The `compute_metrics` function calculates evaluation metrics for classification results.\n",
    "\n",
    "### Inputs\n",
    "- `eval_pred`: A tuple containing two elements:\n",
    "  - `logits`: The raw model outputs (before softmax).\n",
    "  - `labels`: The true class labels.\n",
    "\n",
    "### Process\n",
    "1. Get predicted classes by taking the index with the highest logit value.\n",
    "2. Calculate precision, recall, F1 score, and support for each class separately.\n",
    "3. Create a detailed classification report as a formatted string.\n",
    "4. Compute the confusion matrix showing correct and incorrect predictions per class.\n",
    "5. Prepare a dictionary of metrics including:\n",
    "   - Precision, recall, F1, and support for each class.\n",
    "   - Macro averages (mean) for precision, recall, and F1.\n",
    "   - Overall accuracy.\n",
    "6. Print the confusion matrix and classification report.\n",
    "\n",
    "### Output\n",
    "- Returns a dictionary with all the above metrics, suitable for logging or further analysis.\n",
    "\n",
    "### Notes\n",
    "- `average=None` means metrics are computed separately for each class.\n",
    "- `zero_division=0` avoids errors if some classes have no predicted samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9e6231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=1)\n",
    "\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        labels, predictions, average=None, zero_division=0\n",
    "    )\n",
    "\n",
    "    metrics = {\n",
    "        # per-class\n",
    "        **{f\"precision_class_{i}\": precision[i] for i in range(len(precision))},\n",
    "        **{f\"recall_class_{i}\":    recall[i]    for i in range(len(recall))},\n",
    "        **{f\"f1_class_{i}\":        f1[i]        for i in range(len(f1))},\n",
    "        **{f\"support_class_{i}\":   support[i]   for i in range(len(support))},\n",
    "        # overall\n",
    "        \"precision_macro\": np.mean(precision),\n",
    "        \"recall_macro\":    np.mean(recall),\n",
    "        \"f1_macro\":        np.mean(f1),\n",
    "        \"accuracy\":        (predictions == labels).mean(),\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d441df9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20be9511",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20dd9a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 2e-5\n",
    "batch_size = 16\n",
    "num_epochs = 8\n",
    "\n",
    "output_dir=\"./model_output_dataset_g\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    seed = seed,\n",
    "    output_dir=output_dir,       \n",
    "    num_train_epochs=num_epochs,   \n",
    "    per_device_train_batch_size=batch_size, \n",
    "    per_device_eval_batch_size=batch_size,   \n",
    "    learning_rate=lr,             \n",
    "    warmup_ratio=0.1,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",       \n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"eval_f1_macro\",  \n",
    "    greater_is_better=True   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c91741",
   "metadata": {},
   "source": [
    "## Run trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d406a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,  \n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d80fcdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1304' max='1304' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1304/1304 08:16, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision Class 0</th>\n",
       "      <th>Precision Class 1</th>\n",
       "      <th>Recall Class 0</th>\n",
       "      <th>Recall Class 1</th>\n",
       "      <th>F1 Class 0</th>\n",
       "      <th>F1 Class 1</th>\n",
       "      <th>Support Class 0</th>\n",
       "      <th>Support Class 1</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.296500</td>\n",
       "      <td>0.309560</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.842767</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.879765</td>\n",
       "      <td>0.867314</td>\n",
       "      <td>175</td>\n",
       "      <td>150</td>\n",
       "      <td>0.873191</td>\n",
       "      <td>0.875238</td>\n",
       "      <td>0.873540</td>\n",
       "      <td>0.873846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.193800</td>\n",
       "      <td>0.194982</td>\n",
       "      <td>0.963415</td>\n",
       "      <td>0.894410</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.932153</td>\n",
       "      <td>0.926045</td>\n",
       "      <td>175</td>\n",
       "      <td>150</td>\n",
       "      <td>0.928912</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>0.929099</td>\n",
       "      <td>0.929231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.096100</td>\n",
       "      <td>0.138072</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.972414</td>\n",
       "      <td>0.977143</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.963380</td>\n",
       "      <td>0.955932</td>\n",
       "      <td>175</td>\n",
       "      <td>150</td>\n",
       "      <td>0.961207</td>\n",
       "      <td>0.958571</td>\n",
       "      <td>0.959656</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.178723</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.967930</td>\n",
       "      <td>0.964169</td>\n",
       "      <td>175</td>\n",
       "      <td>150</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.967619</td>\n",
       "      <td>0.966050</td>\n",
       "      <td>0.966154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>0.185302</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.967930</td>\n",
       "      <td>0.964169</td>\n",
       "      <td>175</td>\n",
       "      <td>150</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.967619</td>\n",
       "      <td>0.966050</td>\n",
       "      <td>0.966154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.136498</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.966887</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.974212</td>\n",
       "      <td>0.970100</td>\n",
       "      <td>175</td>\n",
       "      <td>150</td>\n",
       "      <td>0.971949</td>\n",
       "      <td>0.972381</td>\n",
       "      <td>0.972156</td>\n",
       "      <td>0.972308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.144654</td>\n",
       "      <td>0.988166</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.970930</td>\n",
       "      <td>0.967320</td>\n",
       "      <td>175</td>\n",
       "      <td>150</td>\n",
       "      <td>0.968442</td>\n",
       "      <td>0.970476</td>\n",
       "      <td>0.969125</td>\n",
       "      <td>0.969231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.124712</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.965714</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.974063</td>\n",
       "      <td>0.970297</td>\n",
       "      <td>175</td>\n",
       "      <td>150</td>\n",
       "      <td>0.971671</td>\n",
       "      <td>0.972857</td>\n",
       "      <td>0.972180</td>\n",
       "      <td>0.972308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Saving model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model_output_dataset_g\\\\tokenizer_config.json',\n",
       " './model_output_dataset_g\\\\special_tokens_map.json',\n",
       " './model_output_dataset_g\\\\vocab.txt',\n",
       " './model_output_dataset_g\\\\added_tokens.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "\n",
    "try:\n",
    "    train_results = trainer.train()\n",
    "except Exception as e:\n",
    "    print(\"Training failed:\", e)\n",
    "    raise\n",
    "\n",
    "print(\"Training complete. Saving model...\")\n",
    "\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e5e28c",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b7253a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "Validation F1: 0.972\n",
      "Validation Confusion Matrix:\n",
      " [[169   6]\n",
      " [  3 147]]\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9826    0.9657    0.9741       175\n",
      "           1     0.9608    0.9800    0.9703       150\n",
      "\n",
      "    accuracy                         0.9723       325\n",
      "   macro avg     0.9717    0.9729    0.9722       325\n",
      "weighted avg     0.9725    0.9723    0.9723       325\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1: 0.972\n",
      "Test Confusion Matrix:\n",
      " [[167   8]\n",
      " [  1 149]]\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9940    0.9543    0.9738       175\n",
      "           1     0.9490    0.9933    0.9707       150\n",
      "\n",
      "    accuracy                         0.9723       325\n",
      "   macro avg     0.9715    0.9738    0.9722       325\n",
      "weighted avg     0.9733    0.9723    0.9723       325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating model...\")\n",
    "\n",
    "# get metrics only from validation\n",
    "val_results = trainer.evaluate(eval_dataset=val_dataset)\n",
    "print(\"Validation F1:\", round(val_results[\"eval_f1_macro\"], 3))\n",
    "\n",
    "# get predictions and labels for validation\n",
    "val_preds_output = trainer.predict(val_dataset)\n",
    "val_logits = val_preds_output.predictions\n",
    "val_labels = val_preds_output.label_ids\n",
    "val_preds = np.argmax(val_logits, axis=1)\n",
    "\n",
    "# print confusion matrix and classification report for validation\n",
    "print(\"Validation Confusion Matrix:\\n\", confusion_matrix(val_labels, val_preds))\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(val_labels, val_preds, zero_division=0, digits=4))\n",
    "\n",
    "\n",
    "# same for test set\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "print(\"Test F1:\", round(test_results[\"eval_f1_macro\"], 3))\n",
    "\n",
    "test_preds_output = trainer.predict(test_dataset)\n",
    "test_logits = test_preds_output.predictions\n",
    "test_labels = test_preds_output.label_ids\n",
    "test_preds = np.argmax(test_logits, axis=1)\n",
    "\n",
    "print(\"Test Confusion Matrix:\\n\", confusion_matrix(test_labels, test_preds))\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(test_labels, test_preds, zero_division=0, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d97164",
   "metadata": {},
   "source": [
    "# Test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4911a70a",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "099f1b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = output_dir\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a459cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shorten text helper function\n",
    "def shorten(text, max_len=40):\n",
    "    if len(text) <= max_len:\n",
    "        return text\n",
    "    return text[:max_len-3] + \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d8b85d",
   "metadata": {},
   "source": [
    "## My Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    # neutral\n",
    "    (\"Today the weather is beautiful\", \"Heute ist das Wetter schön\", 0), \n",
    "    (\"I like this guy.\", \"Ich mag diesen Kerl.\", 0),\n",
    "    (\"How are you?\", \"Wie geht es dir?\", 0),\n",
    "    (\"BERT is a transformers model pretrained on a large corpus of multilingual data in a self-supervised fashion.\",\"BERT ist ein Transformer-Modell, das auf selbstüberwachte Weise auf einem großen Korpus mehrsprachiger Daten vorab trainiert wird.\",0),\n",
    "    (\"Knowledge is love and light and vision.\",\"Wissen ist Liebe und Licht und Vision.\",0),\n",
    "\n",
    "    # neutral with gendered subjects\n",
    "    (\"My mother is an engineer.\", \"Meine Mutter ist Ingenieurin.\", 0),\n",
    "    (\"Is this boy a good artist?\", \"Ist dieser Junge ein guter Künstler?\", 0),\n",
    "    (\"I am living with my sister, who is also my best friend\", \"Ich lebe mit meiner Schwester, die auch meine beste Freundin ist\", 0),\n",
    "    (\"My father was an excellent cook.\", \"Mein Vater war ein ausgezeichneter Koch.\", 0),\n",
    "    (\"The girls went hiking.\", \"Die Mädchen gingen wandern.\", 0),\n",
    "\n",
    "\n",
    "    # biased\n",
    "    (\"Do you like our maths teacher?\", \"Mögen Sie unsere Mathelehrerin?\", 1),\n",
    "    (\"The doctor was late to work today.\", \"Der Arzt kam heute zu spät zur Arbeit.\", 1),\n",
    "    (\"Tomorrow the students are leaving for a class trip.\", \"Morgen gehen die Studenten zu einer Klassenfahrt.\", 1),\n",
    "    (\"This nurse does not work hard.\", \"Diese Krankenschwester arbeitet nicht hart.\", 1),\n",
    "    (\"Athletes earn a lot of money.\", \"Sportler verdienen viel Geld.\", 1),\n",
    "\n",
    "    # test GFL\n",
    "    (\"Engineers are kind and hard-working\", \"Ingenieur*innen sind lieb und fleißig\", 0),\n",
    "    (\"Engineers are kind and hard-working\", \"Ingenieure und Ingenieurinnen sind lieb und fleißig\", 0),\n",
    "    (\"Teachers are kind and hard-working\", \"Lehrende sind lieb und fleißig\", 0),\n",
    "    (\"Teachers are kind and hard-working\", \"Lehrer:innen sind lieb und fleißig\", 0),\n",
    "    (\"Teachers are kind and hard-working\", \"Lehrerinnen und Lehrer sind lieb und fleißig\", 0),\n",
    "    (\"Teachers are kind and hard-working\", \"Lehrer sind lieb und fleißig\", 1),\n",
    "    (\"Teachers are kind and hard-working\", \"Lehrerinnen sind lieb und fleißig\", 1),\n",
    "\n",
    "    # job posting morgan stanley\n",
    "    (\"We’re seeking someone to join our team Office 365 squads to lead the design, development, and integration of Gen AI apps and integration using Microsoft Copilot Studio.\",\"Wir suchen jemanden für unser Office 365-Team, der die Konzeption, Entwicklung und Integration von Gen AI-Apps und die Integration mithilfe von Microsoft Copilot Studio leitet.\",0),\n",
    "    (\"The ideal candidate should have a solid technical foundation with a focus on Custom agent development and Copilot integrations, strategic thinking, excellent communication skills, and the ability to collaborate within a global team.\", \"Der ideale Kandidat sollte über solide technische Grundlagen mit Schwerpunkt auf der Entwicklung kundenspezifischer Agenten und Copilot-Integrationen, strategisches Denken, ausgezeichnete Kommunikationsfähigkeiten und die Fähigkeit zur Zusammenarbeit in einem globalen Team verfügen.\", 1),\n",
    "    (\"In the Technology division, we leverage innovation to build the connections and capabilities that power our Firm, enabling our clients and colleagues to redefine markets and shape the future of our communities.\", \"Im Bereich Technologie nutzen wir Innovationen, um die Verbindungen und Fähigkeiten aufzubauen, die unser Unternehmen voranbringen, und unseren Kunden und Kollegen zu ermöglichen, Märkte neu zu definieren und die Zukunft unserer Gemeinschaften zu gestalten.\",1),\n",
    "    (\"This is a Lead Workplace Engineering position at VP level, which is part of the job family responsible for managing and optimizing the technical environment and end-user experience across various workplace technologies, ensuring seamless operations and user satisfaction across the organization.\",\"Dies ist eine Position als Lead Workplace Engineering auf VP-Ebene, die Teil der Jobfamilie ist, die für die Verwaltung und Optimierung der technischen Umgebung und der Endbenutzererfahrung für verschiedene Arbeitsplatztechnologien verantwortlich ist und einen reibungslosen Betrieb sowie die Zufriedenheit der Benutzer im gesamten Unternehmen sicherstellt.\",1),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6eaedc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of test cases into a dataframe\n",
    "test_df = pd.DataFrame(test_cases, columns=[\"english\", \"german\", \"label\"])\n",
    "\n",
    "# create BiasDataset instance from dataframe\n",
    "test_dataset = BiasDataset(test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86608a33",
   "metadata": {},
   "source": [
    "## Run Inference on each Test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14badba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    item = test_dataset[i]\n",
    "    \n",
    "    # prepare inputs for model, add batch dimension and move to device\n",
    "    inputs = {key: val.unsqueeze(0).to(device) for key, val in item.items() if key != \"labels\"}\n",
    "    \n",
    "    # run model in evaluation mode without gradients\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        pred_label = torch.argmax(logits, dim=1).item()\n",
    "        prob = torch.softmax(logits, dim=1)[0].cpu().numpy()\n",
    "    \n",
    "    # collect results\n",
    "    results.append({\n",
    "        \"english\": test_df.iloc[i][\"english\"],\n",
    "        \"german\": test_df.iloc[i][\"german\"],\n",
    "        \"true_label\": test_df.iloc[i][\"label\"],\n",
    "        \"predicted_label\": pred_label,\n",
    "        \"neutral_prob\": prob[0],\n",
    "        \"biased_prob\": prob[1],\n",
    "        \"correct\": test_df.iloc[i][\"label\"] == pred_label\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0369a8",
   "metadata": {},
   "source": [
    "## Display Results as Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c5b54b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bias detection test results:\n",
      "                                                                                                                                                                                                                                 english                                                                                                                                                                                                                                                                                      german  true_label  predicted_label  neutral_prob  biased_prob  correct\n",
      "                                                                                                                                                                                                          Today the weather is beautiful                                                                                                                                                                                                                                                                  Heute ist das Wetter schön           0                0      0.999950     0.000050     True\n",
      "                                                                                                                                                                                                                        I like this guy.                                                                                                                                                                                                                                                                        Ich mag diesen Kerl.           0                0      0.999807     0.000193     True\n",
      "                                                                                                                                                                                                                            How are you?                                                                                                                                                                                                                                                                            Wie geht es dir?           0                0      0.999951     0.000049     True\n",
      "                                                                                                                                                                                                                  The girls went hiking.                                                                                                                                                                                                                                                                 Die Mädchen gingen wandern.           0                0      0.999320     0.000680     True\n",
      "                                                                                                                                                                                                               My mother is an engineer.                                                                                                                                                                                                                                                               Meine Mutter ist Ingenieurin.           0                1      0.015515     0.984485    False\n",
      "                                                                                                                                                                                                              Is this boy a good artist?                                                                                                                                                                                                                                                        Ist dieser Junge ein guter Künstler?           0                1      0.013842     0.986158    False\n",
      "                                                                                                                                                                                  I am living with my sister, who is also my best friend                                                                                                                                                                                                                            Ich lebe mit meiner Schwester, die auch meine beste Freundin ist           0                0      0.999943     0.000057     True\n",
      "                                                                                                                                                                                                        My father was an excellent cook.                                                                                                                                                                                                                                                    Mein Vater war ein ausgezeichneter Koch.           0                0      0.998827     0.001173     True\n",
      "                                                                                                                                                                                                          Do you like our maths teacher?                                                                                                                                                                                                                                                             Mögen Sie unsere Mathelehrerin?           1                1      0.039449     0.960551     True\n",
      "                                                                                                                                                                                                      The doctor was late to work today.                                                                                                                                                                                                                                                      Der Arzt kam heute zu spät zur Arbeit.           1                1      0.000069     0.999931     True\n",
      "                                                                                                                                                                                     Tomorrow the students are leaving for a class trip.                                                                                                                                                                                                                                           Morgen gehen die Studenten zu einer Klassenfahrt.           1                1      0.000109     0.999891     True\n",
      "                                                                                                                                                                                                                    Engineers are great.                                                                                                                                                                                                                                                                   Ingenieure sind großartig           1                0      0.886224     0.113776    False\n",
      "                                                                                                                                                                                                          Engineers earn a lot of money.                                                                                                                                                                                                                                                             Ingenieure verdienen viel Geld.           1                1      0.000065     0.999935     True\n",
      "                                                                                                                                                                                                     Engineers are kind and hard-working                                                                                                                                                                                                                                                       Ingenieur*innen sind lieb und fleißig           0                0      0.999328     0.000672     True\n",
      "                                                                                                                                                                                                     Engineers are kind and hard-working                                                                                                                                                                                                                                         Ingenieure und Ingenieurinnen sind lieb und fleißig           0                1      0.000090     0.999910    False\n",
      "                                                                                                                                                                                                      Teachers are kind and hard-working                                                                                                                                                                                                                                                              Lehrende sind lieb und fleißig           0                0      0.999881     0.000119     True\n",
      "                                                                                                                                                                                                      Teachers are kind and hard-working                                                                                                                                                                                                                                                          Lehrer*innen sind lieb und fleißig           0                1      0.212978     0.787022    False\n",
      "                                                                                                                                                                                                      Teachers are kind and hard-working                                                                                                                                                                                                                                                Lehrerinnen und Lehrer sind lieb und fleißig           0                1      0.000069     0.999931    False\n",
      "                                                                                                                                                                                                      Teachers are kind and hard-working                                                                                                                                                                                                                                                                Lehrer sind lieb und fleißig           1                1      0.000142     0.999858     True\n",
      "                                                                                                                                                                                                      Teachers are kind and hard-working                                                                                                                                                                                                                                                           Lehrerinnen sind lieb und fleißig           1                1      0.000107     0.999893     True\n",
      "                                                                 Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another.                                                                                             Googles Software-Ingenieure entwickeln die Technologien der nächsten Generation, die ändern, wie Milliarden von Benutzern verbinden, erkunden, und interagieren mit Informationen und einander.           1                1      0.000119     0.999881     True\n",
      "The ideal candidate should have a solid technical foundation with a focus on Custom agent development and Copilot integrations, strategic thinking, excellent communication skills, and the ability to collaborate within a global team. Der ideale Kandidat sollte über solide technische Grundlagen mit Schwerpunkt auf der Entwicklung kundenspezifischer Agenten und Copilot-Integrationen, strategisches Denken, ausgezeichnete Kommunikationsfähigkeiten und die Fähigkeit zur Zusammenarbeit in einem globalen Team verfügen.           1                1      0.000053     0.999946     True\n",
      "\n",
      "Model accuracy on test cases: 72.7%\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nBias detection test results:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "accuracy = results_df[\"correct\"].mean()\n",
    "print(f\"\\nModel accuracy on test cases: {accuracy:.1%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
