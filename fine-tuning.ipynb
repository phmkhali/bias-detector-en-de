{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3154556d",
   "metadata": {},
   "source": [
    "# Detecting Gender Bias in English-German Translations using Natural Language Processing\n",
    "\n",
    "This notebook presents the bias detection model used for the demonstration. **Minimal documentation and interpretation are provided, as it is intended to be read alongside the thesis.**  \n",
    "\n",
    "The notebook performs the following steps:  \n",
    "1. Reads the created dataset.  \n",
    "2. Loads and trains a multilingual BERT model.  \n",
    "3. Evaluates the model on the held-out dataset and the handcrafted dataset.\n",
    "\n",
    "**Disclaimer:** All results reported in this notebook were obtained using Python 3.12 on a CPU. Do note that results may differ if the notebook is run with other Python versions or on a GPU.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92834f30",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "Standard Python libraries are imported for data handling, computation, and plotting. PyTorch and the Transformers library are used for model training and inference. Evaluation metrics and dataset splitting functions are imported from scikit-learn.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8487e0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khali/Documents/GitHub/bias-detector-en-de-1/thesis-env-3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# standard libraries\n",
    "import os\n",
    "import random\n",
    "\n",
    "# data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# torch and dataset utils\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# transformers library\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "# evaluation and data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e222663",
   "metadata": {},
   "source": [
    "## Set Seed\n",
    "A fixed seed is set for Python, NumPy, and PyTorch random number generators. This ensures that results are reproducible across runs. CUDA deterministic settings are enabled to maintain consistent GPU computations.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "471a072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)                  \n",
    "    np.random.seed(seed)              \n",
    "    torch.manual_seed(seed)           \n",
    "    torch.cuda.manual_seed(seed)      \n",
    "    torch.cuda.manual_seed_all(seed)   \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f6a176",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "The dataset is loaded from a CSV file. This dataset was created using the `join_datasets.py` script located in the `/datasets` directory. It contains sentence pairs with labels indicating whether the translation exhibits gender bias. The first few rows are displayed for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a751c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>german</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The student representatives are responsible.</td>\n",
       "      <td>die Schülervertreter*innen sind verantwortlich.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I also call upon the Ministers, Heads of State...</td>\n",
       "      <td>Ebenso appelliere ich an die Minister sowie an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The deputies are responsible.</td>\n",
       "      <td>Die Stellvertreterinnen sind verantwortlich.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I do not know whether, as one of the speakers ...</td>\n",
       "      <td>Ich weiß nicht, ob ich wie zuvor gesagt wurde,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The reader is responsible.</td>\n",
       "      <td>Die Leserin ist verantwortlich.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0       The student representatives are responsible.   \n",
       "1  I also call upon the Ministers, Heads of State...   \n",
       "2                      The deputies are responsible.   \n",
       "3  I do not know whether, as one of the speakers ...   \n",
       "4                         The reader is responsible.   \n",
       "\n",
       "                                              german  label  \n",
       "0    die Schülervertreter*innen sind verantwortlich.      0  \n",
       "1  Ebenso appelliere ich an die Minister sowie an...      1  \n",
       "2       Die Stellvertreterinnen sind verantwortlich.      1  \n",
       "3  Ich weiß nicht, ob ich wie zuvor gesagt wurde,...      0  \n",
       "4                    Die Leserin ist verantwortlich.      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/dataset.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f54aa9",
   "metadata": {},
   "source": [
    "# Initialize Model\n",
    "\n",
    "The computational device is determined, prioritizing GPU if available. Device information is printed to confirm the configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03cf1013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n",
      "GPU: None (using CPU)\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# print device info\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU: None (using CPU)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bc0e30",
   "metadata": {},
   "source": [
    "## Load Tokenizer\n",
    "The tokenizer corresponding to the selected mBERT model is loaded. This tokenizer is used to convert input text into the token IDs required by the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ba47b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model name\n",
    "model_path = \"bert-base-multilingual-cased\"\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e99331",
   "metadata": {},
   "source": [
    "## Load Model and Send to Device\n",
    "The pre-trained mBERT model is loaded with a sequence classification head configured for binary classification. The model is transferred to the previously selected device for training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f279cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model with classification head\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=2,\n",
    "    id2label={0: \"neutral\", 1: \"biased\"},\n",
    "    label2id={\"neutral\": 0, \"biased\": 1}\n",
    ")\n",
    "\n",
    "# move model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb879bcf",
   "metadata": {},
   "source": [
    "## Freeze Encoder Layers Count Trainable Parameters\n",
    "The first eight encoder layers (layers 0 to 7) of BERT are frozen to reduce training time while allowing higher layers to adapt to the task. Freezing fewer layers increases trainable parameters and flexibility, which was tested in additional experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98bc016c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 121152002\n"
     ]
    }
   ],
   "source": [
    "# freeze encoder layers 0 to 7\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"bert.encoder.layer.\"):\n",
    "        layer_num = int(name.split(\".\")[3])\n",
    "        if layer_num < 8:\n",
    "            param.requires_grad = False\n",
    "\n",
    "# count and print trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable params: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00540c44",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "The EN-DE dataset is prepared for training, validation, and testing. Minimal preprocessing is applied, as the data has already been cleaned and labeled for bias detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84745505",
   "metadata": {},
   "source": [
    "## Custom Dataset Class\n",
    "A custom `BiasDataset` class is defined to handle EN-DE sentence pairs. Each sample is tokenized using the mBERT tokenizer, with the German translation provided as the `text_pair`. The label tensor is included for supervised training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1d237a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom dataset for bias detection\n",
    "class BiasDataset(Dataset):\n",
    "    # init with dataframe and tokenizer\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    # return number of samples\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # return one encoded sample\n",
    "    def __getitem__(self, idx):\n",
    "        english = self.data.iloc[idx][\"english\"]\n",
    "        german = self.data.iloc[idx][\"german\"]\n",
    "        label = int(self.data.iloc[idx][\"label\"])\n",
    "\n",
    "        # tokenize EN-DE sentence pair\n",
    "        encoded = self.tokenizer(\n",
    "            text=english,\n",
    "            text_pair=german,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=256,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # encoded outputs have extra batch dimension, remove it with squeeze(0) to get plain tensors\n",
    "        item = {key: val.squeeze(0) for key, val in encoded.items()}\n",
    "        # add label tensor to the dict under key 'labels'\n",
    "        item[\"labels\"] = torch.tensor(label)\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc28df7",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "The dataset is split into train (80%), validation (10%), and test (10%) sets. Stratified sampling is applied to maintain the label distribution across all splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e171490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train (80%) and temp (20%), keeping label distribution same with stratify\n",
    "train_df, temp_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"label\"],\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# split temp into validation (10%) and test (10%) sets, stratified by label\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_df[\"label\"],\n",
    "    random_state=seed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d06d805",
   "metadata": {},
   "source": [
    "## Create Dataset Objects\n",
    "`BiasDataset` objects are created for the train, validation, and test sets. These objects provide tokenized EN-DE sentence pairs and labels to the model during training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f80e26d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, validation and test datasets\n",
    "train_dataset = BiasDataset(train_df, tokenizer)  \n",
    "val_dataset = BiasDataset(val_df, tokenizer)    \n",
    "test_dataset = BiasDataset(test_df, tokenizer)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d441df9",
   "metadata": {},
   "source": [
    "# Training\n",
    "The mBERT model is trained on the EN-DE bias dataset. The training procedure follows the hyperparameters and setup described below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20be9511",
   "metadata": {},
   "source": [
    "## Training Parameters\n",
    "Hyperparameters are defined for learning rate, batch size, number of epochs, and output directory. TrainingArguments are configured to perform evaluation, logging, and model saving at the end of each epoch. The best model is loaded automatically based on macro F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20dd9a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 2e-5\n",
    "batch_size = 16\n",
    "num_epochs = 8\n",
    "\n",
    "output_dir=\"./model_output\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    seed = seed,\n",
    "    output_dir=output_dir,       \n",
    "    num_train_epochs=num_epochs,   \n",
    "    per_device_train_batch_size=batch_size, \n",
    "    per_device_eval_batch_size=batch_size,   \n",
    "    learning_rate=lr,             \n",
    "    warmup_ratio=0.1,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",       \n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"eval_f1_macro\",  \n",
    "    greater_is_better=True   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a69782b",
   "metadata": {},
   "source": [
    "## Evaluation Metrics Calculation for Classification\n",
    "A custom metric function is defined to calculate precision, recall, F1 score, and support for each class. Macro averages and overall accuracy are also computed to allow consistent evaluation across training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "049aa80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=1)\n",
    "\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        labels, predictions, average=None, zero_division=0\n",
    "    )\n",
    "\n",
    "    metrics = {\n",
    "        # per-class\n",
    "        **{f\"precision_class_{i}\": precision[i] for i in range(len(precision))},\n",
    "        **{f\"recall_class_{i}\":    recall[i]    for i in range(len(recall))},\n",
    "        **{f\"f1_class_{i}\":        f1[i]        for i in range(len(f1))},\n",
    "        **{f\"support_class_{i}\":   support[i]   for i in range(len(support))},\n",
    "        # overall\n",
    "        \"precision_macro\": np.mean(precision),\n",
    "        \"recall_macro\":    np.mean(recall),\n",
    "        \"f1_macro\":        np.mean(f1),\n",
    "        \"accuracy\":        (predictions == labels).mean(),\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c91741",
   "metadata": {},
   "source": [
    "## Run trainer\n",
    "A `Trainer` object is instantiated with the model, datasets, training arguments, metric function, and early stopping callback. Training is executed with exception handling. After completion, the trained model and tokenizer are saved to the specified output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d406a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,  \n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d80fcdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khali/Documents/GitHub/bias-detector-en-de-1/thesis-env-3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='978' max='1304' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 978/1304 20:38 < 06:53, 0.79 it/s, Epoch 6/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision Class 0</th>\n",
       "      <th>Precision Class 1</th>\n",
       "      <th>Recall Class 0</th>\n",
       "      <th>Recall Class 1</th>\n",
       "      <th>F1 Class 0</th>\n",
       "      <th>F1 Class 1</th>\n",
       "      <th>Support Class 0</th>\n",
       "      <th>Support Class 1</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.367436</td>\n",
       "      <td>0.909677</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.805714</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>175</td>\n",
       "      <td>150</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.856190</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.852308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.272900</td>\n",
       "      <td>0.167946</td>\n",
       "      <td>0.969136</td>\n",
       "      <td>0.889571</td>\n",
       "      <td>0.897143</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.931751</td>\n",
       "      <td>0.926518</td>\n",
       "      <td>175</td>\n",
       "      <td>150</td>\n",
       "      <td>0.929353</td>\n",
       "      <td>0.931905</td>\n",
       "      <td>0.929134</td>\n",
       "      <td>0.929231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.147580</td>\n",
       "      <td>0.950276</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.982857</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>175</td>\n",
       "      <td>150</td>\n",
       "      <td>0.964721</td>\n",
       "      <td>0.961429</td>\n",
       "      <td>0.962738</td>\n",
       "      <td>0.963077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.147034</td>\n",
       "      <td>0.988304</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.965714</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.976879</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>175</td>\n",
       "      <td>150</td>\n",
       "      <td>0.974672</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.975281</td>\n",
       "      <td>0.975385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.050900</td>\n",
       "      <td>0.141204</td>\n",
       "      <td>0.988304</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.965714</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.976879</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>175</td>\n",
       "      <td>150</td>\n",
       "      <td>0.974672</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.975281</td>\n",
       "      <td>0.975385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.173657</td>\n",
       "      <td>0.960227</td>\n",
       "      <td>0.959732</td>\n",
       "      <td>0.965714</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>175</td>\n",
       "      <td>150</td>\n",
       "      <td>0.959979</td>\n",
       "      <td>0.959524</td>\n",
       "      <td>0.959742</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "/Users/khali/Documents/GitHub/bias-detector-en-de-1/thesis-env-3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "/Users/khali/Documents/GitHub/bias-detector-en-de-1/thesis-env-3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "/Users/khali/Documents/GitHub/bias-detector-en-de-1/thesis-env-3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "/Users/khali/Documents/GitHub/bias-detector-en-de-1/thesis-env-3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "/Users/khali/Documents/GitHub/bias-detector-en-de-1/thesis-env-3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Saving model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model_output/tokenizer_config.json',\n",
       " './model_output/special_tokens_map.json',\n",
       " './model_output/vocab.txt',\n",
       " './model_output/added_tokens.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "\n",
    "try:\n",
    "    train_results = trainer.train()\n",
    "except Exception as e:\n",
    "    print(\"Training failed:\", e)\n",
    "    raise\n",
    "\n",
    "print(\"Training complete. Saving model...\")\n",
    "\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9924b0",
   "metadata": {},
   "source": [
    "Training stopped early because the validation F1-macro did not improve after epoch 6. The best model was selected based on the highest F1-macro score, which reached 0.9753.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e5e28c",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "The trained mBERT model is evaluated on the validation and test sets. Both overall performance metrics and detailed error analyses are computed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02efd18",
   "metadata": {},
   "source": [
    "## Evaluation Metrics and Confusion Rates\n",
    "\n",
    "A function is defined to compute confusion matrix components and false positive/negative rates. The `evaluate_and_print` function performs evaluation on a given dataset, prints the macro F1 score, confusion matrix, error rates, and a detailed classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b7253a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "\n",
      "Evaluating on Validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khali/Documents/GitHub/bias-detector-en-de-1/thesis-env-3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khali/Documents/GitHub/bias-detector-en-de-1/thesis-env-3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Confusion Matrix:\n",
      "TN=169, FP=6, FN=2, TP=148\n",
      "False Positive Rate=0.034, False Negative Rate=0.013\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9883    0.9657    0.9769       175\n",
      "           1     0.9610    0.9867    0.9737       150\n",
      "\n",
      "    accuracy                         0.9754       325\n",
      "   macro avg     0.9747    0.9762    0.9753       325\n",
      "weighted avg     0.9757    0.9754    0.9754       325\n",
      "\n",
      "\n",
      "Evaluating on Test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khali/Documents/GitHub/bias-detector-en-de-1/thesis-env-3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1: 0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khali/Documents/GitHub/bias-detector-en-de-1/thesis-env-3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Confusion Matrix:\n",
      "TN=165, FP=10, FN=1, TP=149\n",
      "False Positive Rate=0.057, False Negative Rate=0.007\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9940    0.9429    0.9677       175\n",
      "           1     0.9371    0.9933    0.9644       150\n",
      "\n",
      "    accuracy                         0.9662       325\n",
      "   macro avg     0.9655    0.9681    0.9661       325\n",
      "weighted avg     0.9677    0.9662    0.9662       325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_rates(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    fp_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    fn_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    return tn, fp, fn, tp, fp_rate, fn_rate\n",
    "\n",
    "def evaluate_and_print(trainer, dataset, name):\n",
    "    print(f\"\\nEvaluating on {name} set...\")\n",
    "\n",
    "    # Evaluate with compute_metrics\n",
    "    results = trainer.evaluate(eval_dataset=dataset)\n",
    "    print(f\"{name} F1:\", round(results[\"eval_f1_macro\"], 3))\n",
    "\n",
    "    # Get raw predictions and labels\n",
    "    output = trainer.predict(dataset)\n",
    "    logits = output.predictions\n",
    "    labels = output.label_ids\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    # Confusion matrix breakdown\n",
    "    tn, fp, fn, tp, fp_rate, fn_rate = compute_rates(labels, preds)\n",
    "    print(f\"{name} Confusion Matrix:\")\n",
    "    print(f\"TN={tn}, FP={fp}, FN={fn}, TP={tp}\")\n",
    "    print(f\"False Positive Rate={fp_rate:.3f}, False Negative Rate={fn_rate:.3f}\")\n",
    "\n",
    "    # Classification report\n",
    "    print(f\"\\n{name} Classification Report:\\n\",\n",
    "          classification_report(labels, preds, zero_division=0, digits=4))\n",
    "\n",
    "    return output  # Optional, in case you want to reuse preds later\n",
    "\n",
    "# ---- Main Evaluation ----\n",
    "print(\"Evaluating model...\")\n",
    "\n",
    "val_output  = evaluate_and_print(trainer, val_dataset,  \"Validation\")\n",
    "test_output = evaluate_and_print(trainer, test_dataset, \"Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d2fafd",
   "metadata": {},
   "source": [
    "## Detailed Error Analysis\n",
    "\n",
    "Predictions on the test set are combined with the corresponding EN-DE sentence pairs and true labels. False positives and false negatives are identified to allow inspection of model errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f3e965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts_en = test_dataset.data[\"english\"].tolist()\n",
    "test_texts_de = test_dataset.data[\"german\"].tolist()\n",
    "\n",
    "test_labels = test_output.label_ids\n",
    "test_preds  = np.argmax(test_output.predictions, axis=1)\n",
    "\n",
    "analysis_df = pd.DataFrame({\n",
    "    \"text_en\":    test_texts_en,\n",
    "    \"text_de\":    test_texts_de,\n",
    "    \"true_label\": test_labels,\n",
    "    \"pred_label\": test_preds\n",
    "})\n",
    "\n",
    "fp_df = analysis_df[(analysis_df.true_label == 0) & (analysis_df.pred_label == 1)]\n",
    "fn_df = analysis_df[(analysis_df.true_label == 1) & (analysis_df.pred_label == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14a65bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error Type</th>\n",
       "      <th>English Text</th>\n",
       "      <th>German Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False Positive</td>\n",
       "      <td>Accordingly, the President of the French Republic, the President of the European Council and the French Prime Minister asked me to visit, before the President of the French Republic, the ten countries which are currently asking for only one commissioner.</td>\n",
       "      <td>In diesem Sinne haben das Oberhaupt der Republik, die Präsidentschaft des Europäischen Rates und das französische Regierungsoberhaupt mich beauftragt, vor der Rundreise des Oberhaupts der Republik die zehn Länder aufzusuchen, die gegenwärtig nur einen Kommissionssitz beanspruchen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False Positive</td>\n",
       "      <td>In so doing, we are beginning to train the next generation of police officers to work and operate throughout Europe; in other words, we will be preparing them to implement Community law and joint and Community actions.</td>\n",
       "      <td>Wir beginnen also jetzt mit der Ausbildung der nächsten Generation von Polizeibeamteten, die in der Lage sein sollen, auf europäischer Ebene zu arbeiten und zu handeln, d. h. sie werden darauf vorbereitet, das Gemeinschaftsrecht anzuwenden und die gemeinsamen und gemeinschaftlichen Maßnahmen umzusetzen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False Positive</td>\n",
       "      <td>The Heads of State and Government therefore agreed a number of measures to promote the development of risk capital in the European Union, with a deadline for implementing the Risk Capital Action Plan of 2003.</td>\n",
       "      <td>Die Staats - und Regierungoberhäupter beschlossen deshalb eine Reihe von Maßnahmen zur Förderung der Entwicklung von Risikokapital in der Europäischen Union, um den Risikokapital - Aktionsplan bis zum Jahr 2003 vollständig umzusetzen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False Positive</td>\n",
       "      <td>We will, over the coming weeks, have to take account of the results of the dialogue between the two political leaders, or of the absence of such a dialogue.</td>\n",
       "      <td>In den kommenden Wochen werden wir die Ergebnisse des Dialogs zwischen den beiden politischen Spitzen bzw. das Ausbleiben eines solchen Dialogs zur Kenntnis nehmen müssen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False Positive</td>\n",
       "      <td>Would you go for treatment to somebody who knows all the surgical terms in Italian, English, French and German, or would you go to a surgeon?</td>\n",
       "      <td>Würden Sie sich von einem Menschen, der sich ausgezeichnet in den chirurgischen Fachbegriffen in Italienisch, Französisch und Deutsch auskennt, oder von einem Menschen, der als Chirurg ausgebildet wurde, operieren lassen?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False Positive</td>\n",
       "      <td>I have just been to the station to see my uncle off.</td>\n",
       "      <td>Ich war gerade am Bahnhof, um mich von meinem Onkel zu verabschieden.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False Positive</td>\n",
       "      <td>The specialists are intelligent.</td>\n",
       "      <td>Die Sachkundigen sind intelligent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False Positive</td>\n",
       "      <td>The recipient is responsible.</td>\n",
       "      <td>Rezipierende ist verantwortlich.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False Positive</td>\n",
       "      <td>What we still need are more experts to guide our companies through complex procedures at European level.</td>\n",
       "      <td>Was wir noch brauchen, sind weitere Fachleute, die unseren Betrieben in schwierigen Prozessen auf europäischer Ebene helfen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False Positive</td>\n",
       "      <td>I shall try very briefly to pinpoint a few political aspects of the four areas touched on in greater or lesser detail by all the speakers, i.e. the new political approach in the social agenda, secondly the content, thirdly the means and fourthly the procedures.</td>\n",
       "      <td>Ich werde versuchen, in aller Kürze einige politische Bemerkungen zu den vier Themenbereichen vorzutragen, die mehr oder weniger ausführlich von allen, die das Wort hatten, angesprochen wurden. Es sind dies erstens das neue politische Konzept der sozialpolitischen Agenda, zweitens der Inhalt, drittens die Mittel und viertens die Verfahren.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False Negative</td>\n",
       "      <td>Here too the local people are frustrated by the immigration of Muslims and the hard line taken by the military.</td>\n",
       "      <td>Hier wird die lokale Bevölkerung ebenfalls durch die Zuwanderung von Muslimen und das unnachsichtige Auftreten des Militärs schwer gebeutelt.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Error Type  \\\n",
       "0   False Positive   \n",
       "1   False Positive   \n",
       "2   False Positive   \n",
       "3   False Positive   \n",
       "4   False Positive   \n",
       "5   False Positive   \n",
       "6   False Positive   \n",
       "7   False Positive   \n",
       "8   False Positive   \n",
       "9   False Positive   \n",
       "10  False Negative   \n",
       "\n",
       "                                                                                                                                                                                                                                                             English Text  \\\n",
       "0          Accordingly, the President of the French Republic, the President of the European Council and the French Prime Minister asked me to visit, before the President of the French Republic, the ten countries which are currently asking for only one commissioner.   \n",
       "1                                              In so doing, we are beginning to train the next generation of police officers to work and operate throughout Europe; in other words, we will be preparing them to implement Community law and joint and Community actions.   \n",
       "2                                                        The Heads of State and Government therefore agreed a number of measures to promote the development of risk capital in the European Union, with a deadline for implementing the Risk Capital Action Plan of 2003.   \n",
       "3                                                                                                            We will, over the coming weeks, have to take account of the results of the dialogue between the two political leaders, or of the absence of such a dialogue.   \n",
       "4                                                                                                                           Would you go for treatment to somebody who knows all the surgical terms in Italian, English, French and German, or would you go to a surgeon?   \n",
       "5                                                                                                                                                                                                                    I have just been to the station to see my uncle off.   \n",
       "6                                                                                                                                                                                                                                        The specialists are intelligent.   \n",
       "7                                                                                                                                                                                                                                           The recipient is responsible.   \n",
       "8                                                                                                                                                                What we still need are more experts to guide our companies through complex procedures at European level.   \n",
       "9   I shall try very briefly to pinpoint a few political aspects of the four areas touched on in greater or lesser detail by all the speakers, i.e. the new political approach in the social agenda, secondly the content, thirdly the means and fourthly the procedures.   \n",
       "10                                                                                                                                                        Here too the local people are frustrated by the immigration of Muslims and the hard line taken by the military.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                              German Text  \n",
       "0                                                               In diesem Sinne haben das Oberhaupt der Republik, die Präsidentschaft des Europäischen Rates und das französische Regierungsoberhaupt mich beauftragt, vor der Rundreise des Oberhaupts der Republik die zehn Länder aufzusuchen, die gegenwärtig nur einen Kommissionssitz beanspruchen.  \n",
       "1                                        Wir beginnen also jetzt mit der Ausbildung der nächsten Generation von Polizeibeamteten, die in der Lage sein sollen, auf europäischer Ebene zu arbeiten und zu handeln, d. h. sie werden darauf vorbereitet, das Gemeinschaftsrecht anzuwenden und die gemeinsamen und gemeinschaftlichen Maßnahmen umzusetzen.  \n",
       "2                                                                                                              Die Staats - und Regierungoberhäupter beschlossen deshalb eine Reihe von Maßnahmen zur Förderung der Entwicklung von Risikokapital in der Europäischen Union, um den Risikokapital - Aktionsplan bis zum Jahr 2003 vollständig umzusetzen.  \n",
       "3                                                                                                                                                                             In den kommenden Wochen werden wir die Ergebnisse des Dialogs zwischen den beiden politischen Spitzen bzw. das Ausbleiben eines solchen Dialogs zur Kenntnis nehmen müssen.  \n",
       "4                                                                                                                           Würden Sie sich von einem Menschen, der sich ausgezeichnet in den chirurgischen Fachbegriffen in Italienisch, Französisch und Deutsch auskennt, oder von einem Menschen, der als Chirurg ausgebildet wurde, operieren lassen?  \n",
       "5                                                                                                                                                                                                                                                                                   Ich war gerade am Bahnhof, um mich von meinem Onkel zu verabschieden.  \n",
       "6                                                                                                                                                                                                                                                                                                                      Die Sachkundigen sind intelligent.  \n",
       "7                                                                                                                                                                                                                                                                                                                        Rezipierende ist verantwortlich.  \n",
       "8                                                                                                                                                                                                                            Was wir noch brauchen, sind weitere Fachleute, die unseren Betrieben in schwierigen Prozessen auf europäischer Ebene helfen.  \n",
       "9   Ich werde versuchen, in aller Kürze einige politische Bemerkungen zu den vier Themenbereichen vorzutragen, die mehr oder weniger ausführlich von allen, die das Wort hatten, angesprochen wurden. Es sind dies erstens das neue politische Konzept der sozialpolitischen Agenda, zweitens der Inhalt, drittens die Mittel und viertens die Verfahren.  \n",
       "10                                                                                                                                                                                                          Hier wird die lokale Bevölkerung ebenfalls durch die Zuwanderung von Muslimen und das unnachsichtige Auftreten des Militärs schwer gebeutelt.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "combined_df = pd.concat([\n",
    "    fp_df.assign(Error='False Positive'),\n",
    "    fn_df.assign(Error='False Negative')\n",
    "], ignore_index=True)[['Error', 'text_en', 'text_de']]\n",
    "\n",
    "combined_df.columns = ['Error Type', 'English Text', 'German Text']\n",
    "\n",
    "display(combined_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233d08fb",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "A confusion matrix is visualized with both counts and percentages. This provides an overview of the model's performance on the test set, highlighting misclassifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c576f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_confusion_matrix_counts_percent(y_true, y_pred, title=\"Confusion Matrix\"):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_percent = cm / cm.sum(axis=1, keepdims=True) * 100\n",
    "    labels = ['Negative (0)', 'Positive (1)']\n",
    "\n",
    "    annot = [[f\"{cm[i, j]}\\n({cm_percent[i, j]:.1f}%)\" for j in range(cm.shape[1])] for i in range(cm.shape[0])]\n",
    "    \n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=annot, fmt='', cmap='Reds',\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix_counts_percent(test_labels, test_preds, title=\"Test Set Confusion Matrix\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d97164",
   "metadata": {},
   "source": [
    "# Test cases\n",
    "The trained mBERT model is evaluated on handcrafted test sentences. These sentences cover various bias patterns and scenarios, allowing inspection of the model's behavior beyond the standard test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4911a70a",
   "metadata": {},
   "source": [
    "## Load trained model\n",
    "The model and tokenizer are loaded from the saved output directory and set to evaluation mode. This ensures that inference is performed without gradient updates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "099f1b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"./model_output\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a459cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shorten text helper function\n",
    "def shorten(text, max_len=40):\n",
    "    if len(text) <= max_len:\n",
    "        return text\n",
    "    return text[:max_len-3] + \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d8b85d",
   "metadata": {},
   "source": [
    "## Handcrafted Test Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeba3b5",
   "metadata": {},
   "source": [
    "A set of EN-DE sentence pairs is defined. Each pair is labeled as:  \n",
    "- 0 = neutral (no gender bias)  \n",
    "- 1 = biased (translation contains gender bias)  \n",
    "\n",
    "The test cases include neutral sentences, neutral sentences with gendered subjects, stereotypically biased sentences, gender-fair language (GFL) examples, and job posting examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "494c888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    # neutral\n",
    "    (\"Today the weather is beautiful\", \"Heute ist das Wetter schön\", 0), \n",
    "    (\"I like this guy.\", \"Ich mag diesen Kerl.\", 0),\n",
    "    (\"How are you?\", \"Wie geht es dir?\", 0),\n",
    "    (\"BERT is a transformers model pretrained on a large corpus of multilingual data in a self-supervised fashion.\",\"BERT ist ein Transformer-Modell, das auf selbstüberwachte Weise auf einem großen Korpus mehrsprachiger Daten vorab trainiert wird.\",0),\n",
    "    (\"Knowledge is love and light and vision.\",\"Wissen ist Liebe und Licht und Vision.\",0),\n",
    "\n",
    "    # neutral with gendered subjects\n",
    "    (\"My mother is an engineer.\", \"Meine Mutter ist Ingenieurin.\", 0),\n",
    "    (\"Is this boy a good artist?\", \"Ist dieser Junge ein guter Künstler?\", 0),\n",
    "    (\"I am living with my sister, who is also my best friend\", \"Ich lebe mit meiner Schwester, die auch meine beste Freundin ist\", 0),\n",
    "    (\"My father was an excellent cook.\", \"Mein Vater war ein ausgezeichneter Koch.\", 0),\n",
    "    (\"The girls went hiking.\", \"Die Mädchen gingen wandern.\", 0),\n",
    "\n",
    "\n",
    "    # biased\n",
    "    (\"Do you like our maths teacher?\", \"Mögen Sie unsere Mathelehrerin?\", 1),\n",
    "    (\"The doctor was late to work today.\", \"Der Arzt kam heute zu spät zur Arbeit.\", 1),\n",
    "    (\"Tomorrow the students are leaving for a class trip.\", \"Morgen gehen die Studenten zu einer Klassenfahrt.\", 1),\n",
    "    (\"This nurse does not work hard.\", \"Diese Krankenschwester arbeitet nicht hart.\", 1),\n",
    "    (\"Athletes earn a lot of money.\", \"Sportler verdienen viel Geld.\", 1),\n",
    "\n",
    "    # test GFL\n",
    "    (\"Engineers are kind and hard-working\", \"Ingenieur*innen sind lieb und fleißig\", 0),\n",
    "    (\"Engineers are kind and hard-working\", \"Ingenieure und Ingenieurinnen sind lieb und fleißig\", 0),\n",
    "    (\"Teachers are kind and hard-working\", \"Lehrende sind lieb und fleißig\", 0),\n",
    "    (\"Teachers are kind and hard-working\", \"Lehrer:innen sind lieb und fleißig\", 0),\n",
    "    (\"Teachers are kind and hard-working\", \"Lehrerinnen und Lehrer sind lieb und fleißig\", 0),\n",
    "    (\"Teachers are kind and hard-working\", \"Lehrer sind lieb und fleißig\", 1),\n",
    "    (\"Teachers are kind and hard-working\", \"Lehrerinnen sind lieb und fleißig\", 1),\n",
    "\n",
    "    # job posting morgan stanley\n",
    "    (\"We’re seeking someone to join our team Office 365 squads to lead the design, development, and integration of Gen AI apps and integration using Microsoft Copilot Studio.\",\"Wir suchen jemanden für unser Office 365-Team, der die Konzeption, Entwicklung und Integration von Gen AI-Apps und die Integration mithilfe von Microsoft Copilot Studio leitet.\",0),\n",
    "    (\"The ideal candidate should have a solid technical foundation with a focus on Custom agent development and Copilot integrations, strategic thinking, excellent communication skills, and the ability to collaborate within a global team.\", \"Der ideale Kandidat sollte über solide technische Grundlagen mit Schwerpunkt auf der Entwicklung kundenspezifischer Agenten und Copilot-Integrationen, strategisches Denken, ausgezeichnete Kommunikationsfähigkeiten und die Fähigkeit zur Zusammenarbeit in einem globalen Team verfügen.\", 1),\n",
    "    (\"In the Technology division, we leverage innovation to build the connections and capabilities that power our Firm, enabling our clients and colleagues to redefine markets and shape the future of our communities.\", \"Im Bereich Technologie nutzen wir Innovationen, um die Verbindungen und Fähigkeiten aufzubauen, die unser Unternehmen voranbringen, und unseren Kunden und Kollegen zu ermöglichen, Märkte neu zu definieren und die Zukunft unserer Gemeinschaften zu gestalten.\",1),\n",
    "    (\"This is a Lead Workplace Engineering position at VP level, which is part of the job family responsible for managing and optimizing the technical environment and end-user experience across various workplace technologies, ensuring seamless operations and user satisfaction across the organization.\",\"Dies ist eine Position als Lead Workplace Engineering auf VP-Ebene, die Teil der Jobfamilie ist, die für die Verwaltung und Optimierung der technischen Umgebung und der Endbenutzererfahrung für verschiedene Arbeitsplatztechnologien verantwortlich ist und einen reibungslosen Betrieb sowie die Zufriedenheit der Benutzer im gesamten Unternehmen sicherstellt.\",1),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8f3dc8",
   "metadata": {},
   "source": [
    "## Prepare Dataset\n",
    "\n",
    "The handcrafted sentences are converted into a `BiasDataset` instance. This allows tokenization and structured input to the model for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6eaedc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of test cases into a dataframe\n",
    "test_df = pd.DataFrame(test_cases, columns=[\"english\", \"german\", \"label\"])\n",
    "\n",
    "# create BiasDataset instance from dataframe\n",
    "test_dataset = BiasDataset(test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86608a33",
   "metadata": {},
   "source": [
    "## Run Inference on Each Test Case\n",
    "\n",
    "Each handcrafted sentence is passed through mBERT. Predictions, probabilities, and correctness indicators are collected for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14badba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    item = test_dataset[i]\n",
    "    \n",
    "    # prepare inputs for model, add batch dimension and move to device\n",
    "    inputs = {key: val.unsqueeze(0).to(device) for key, val in item.items() if key != \"labels\"}\n",
    "    \n",
    "    # run model in evaluation mode without gradients\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        pred_label = torch.argmax(logits, dim=1).item()\n",
    "        prob = torch.softmax(logits, dim=1)[0].cpu().numpy()\n",
    "    \n",
    "    # collect results\n",
    "    results.append({\n",
    "        \"english\": test_df.iloc[i][\"english\"],\n",
    "        \"german\": test_df.iloc[i][\"german\"],\n",
    "        \"true_label\": test_df.iloc[i][\"label\"],\n",
    "        \"predicted_label\": pred_label,\n",
    "        \"neutral_prob\": prob[0],\n",
    "        \"biased_prob\": prob[1],\n",
    "        \"correct\": test_df.iloc[i][\"label\"] == pred_label\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0369a8",
   "metadata": {},
   "source": [
    "## Display Results\n",
    "Results are summarized in a table showing English and German texts, true and predicted labels, probabilities for each class, and correctness. Overall model accuracy on the handcrafted test cases is reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c5b54b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bias detection test results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>german</th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>neutral_prob</th>\n",
       "      <th>biased_prob</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today the weather is beautiful</td>\n",
       "      <td>Heute ist das Wetter schön</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999575</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I like this guy.</td>\n",
       "      <td>Ich mag diesen Kerl.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999731</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How are you?</td>\n",
       "      <td>Wie geht es dir?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999805</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BERT is a transformers model pretrained on a large corpus of multilingual data in a self-supervised fashion.</td>\n",
       "      <td>BERT ist ein Transformer-Modell, das auf selbstüberwachte Weise auf einem großen Korpus mehrsprachiger Daten vorab trainiert wird.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688832</td>\n",
       "      <td>0.311168</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Knowledge is love and light and vision.</td>\n",
       "      <td>Wissen ist Liebe und Licht und Vision.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999234</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>My mother is an engineer.</td>\n",
       "      <td>Meine Mutter ist Ingenieurin.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.441243</td>\n",
       "      <td>0.558757</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Is this boy a good artist?</td>\n",
       "      <td>Ist dieser Junge ein guter Künstler?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.622386</td>\n",
       "      <td>0.377614</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I am living with my sister, who is also my best friend</td>\n",
       "      <td>Ich lebe mit meiner Schwester, die auch meine beste Freundin ist</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998843</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>My father was an excellent cook.</td>\n",
       "      <td>Mein Vater war ein ausgezeichneter Koch.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907980</td>\n",
       "      <td>0.092020</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The girls went hiking.</td>\n",
       "      <td>Die Mädchen gingen wandern.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998616</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Do you like our maths teacher?</td>\n",
       "      <td>Mögen Sie unsere Mathelehrerin?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.091663</td>\n",
       "      <td>0.908337</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The doctor was late to work today.</td>\n",
       "      <td>Der Arzt kam heute zu spät zur Arbeit.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.999331</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tomorrow the students are leaving for a class trip.</td>\n",
       "      <td>Morgen gehen die Studenten zu einer Klassenfahrt.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.999321</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This nurse does not work hard.</td>\n",
       "      <td>Diese Krankenschwester arbeitet nicht hart.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.998276</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Athletes earn a lot of money.</td>\n",
       "      <td>Sportler verdienen viel Geld.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.998782</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Engineers are kind and hard-working</td>\n",
       "      <td>Ingenieur*innen sind lieb und fleißig</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.954139</td>\n",
       "      <td>0.045861</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Engineers are kind and hard-working</td>\n",
       "      <td>Ingenieure und Ingenieurinnen sind lieb und fleißig</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.999160</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Teachers are kind and hard-working</td>\n",
       "      <td>Lehrende sind lieb und fleißig</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997319</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Teachers are kind and hard-working</td>\n",
       "      <td>Lehrer:innen sind lieb und fleißig</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031357</td>\n",
       "      <td>0.968643</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Teachers are kind and hard-working</td>\n",
       "      <td>Lehrerinnen und Lehrer sind lieb und fleißig</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.999465</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Teachers are kind and hard-working</td>\n",
       "      <td>Lehrer sind lieb und fleißig</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.999162</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Teachers are kind and hard-working</td>\n",
       "      <td>Lehrerinnen sind lieb und fleißig</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.999321</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>We’re seeking someone to join our team Office 365 squads to lead the design, development, and integration of Gen AI apps and integration using Microsoft Copilot Studio.</td>\n",
       "      <td>Wir suchen jemanden für unser Office 365-Team, der die Konzeption, Entwicklung und Integration von Gen AI-Apps und die Integration mithilfe von Microsoft Copilot Studio leitet.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996394</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The ideal candidate should have a solid technical foundation with a focus on Custom agent development and Copilot integrations, strategic thinking, excellent communication skills, and the ability to collaborate within a global team.</td>\n",
       "      <td>Der ideale Kandidat sollte über solide technische Grundlagen mit Schwerpunkt auf der Entwicklung kundenspezifischer Agenten und Copilot-Integrationen, strategisches Denken, ausgezeichnete Kommunikationsfähigkeiten und die Fähigkeit zur Zusammenarbeit in einem globalen Team verfügen.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.999376</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>In the Technology division, we leverage innovation to build the connections and capabilities that power our Firm, enabling our clients and colleagues to redefine markets and shape the future of our communities.</td>\n",
       "      <td>Im Bereich Technologie nutzen wir Innovationen, um die Verbindungen und Fähigkeiten aufzubauen, die unser Unternehmen voranbringen, und unseren Kunden und Kollegen zu ermöglichen, Märkte neu zu definieren und die Zukunft unserer Gemeinschaften zu gestalten.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.999598</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>This is a Lead Workplace Engineering position at VP level, which is part of the job family responsible for managing and optimizing the technical environment and end-user experience across various workplace technologies, ensuring seamless operations and user satisfaction across the organization.</td>\n",
       "      <td>Dies ist eine Position als Lead Workplace Engineering auf VP-Ebene, die Teil der Jobfamilie ist, die für die Verwaltung und Optimierung der technischen Umgebung und der Endbenutzererfahrung für verschiedene Arbeitsplatztechnologien verantwortlich ist und einen reibungslosen Betrieb sowie die Zufriedenheit der Benutzer im gesamten Unternehmen sicherstellt.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.998478</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                    english  \\\n",
       "0                                                                                                                                                                                                                                                                            Today the weather is beautiful   \n",
       "1                                                                                                                                                                                                                                                                                          I like this guy.   \n",
       "2                                                                                                                                                                                                                                                                                              How are you?   \n",
       "3                                                                                                                                                                                              BERT is a transformers model pretrained on a large corpus of multilingual data in a self-supervised fashion.   \n",
       "4                                                                                                                                                                                                                                                                   Knowledge is love and light and vision.   \n",
       "5                                                                                                                                                                                                                                                                                 My mother is an engineer.   \n",
       "6                                                                                                                                                                                                                                                                                Is this boy a good artist?   \n",
       "7                                                                                                                                                                                                                                                    I am living with my sister, who is also my best friend   \n",
       "8                                                                                                                                                                                                                                                                          My father was an excellent cook.   \n",
       "9                                                                                                                                                                                                                                                                                    The girls went hiking.   \n",
       "10                                                                                                                                                                                                                                                                           Do you like our maths teacher?   \n",
       "11                                                                                                                                                                                                                                                                       The doctor was late to work today.   \n",
       "12                                                                                                                                                                                                                                                      Tomorrow the students are leaving for a class trip.   \n",
       "13                                                                                                                                                                                                                                                                           This nurse does not work hard.   \n",
       "14                                                                                                                                                                                                                                                                            Athletes earn a lot of money.   \n",
       "15                                                                                                                                                                                                                                                                      Engineers are kind and hard-working   \n",
       "16                                                                                                                                                                                                                                                                      Engineers are kind and hard-working   \n",
       "17                                                                                                                                                                                                                                                                       Teachers are kind and hard-working   \n",
       "18                                                                                                                                                                                                                                                                       Teachers are kind and hard-working   \n",
       "19                                                                                                                                                                                                                                                                       Teachers are kind and hard-working   \n",
       "20                                                                                                                                                                                                                                                                       Teachers are kind and hard-working   \n",
       "21                                                                                                                                                                                                                                                                       Teachers are kind and hard-working   \n",
       "22                                                                                                                                 We’re seeking someone to join our team Office 365 squads to lead the design, development, and integration of Gen AI apps and integration using Microsoft Copilot Studio.   \n",
       "23                                                                 The ideal candidate should have a solid technical foundation with a focus on Custom agent development and Copilot integrations, strategic thinking, excellent communication skills, and the ability to collaborate within a global team.   \n",
       "24                                                                                       In the Technology division, we leverage innovation to build the connections and capabilities that power our Firm, enabling our clients and colleagues to redefine markets and shape the future of our communities.   \n",
       "25  This is a Lead Workplace Engineering position at VP level, which is part of the job family responsible for managing and optimizing the technical environment and end-user experience across various workplace technologies, ensuring seamless operations and user satisfaction across the organization.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                   german  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                              Heute ist das Wetter schön   \n",
       "1                                                                                                                                                                                                                                                                                                                                                    Ich mag diesen Kerl.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                        Wie geht es dir?   \n",
       "3                                                                                                                                                                                                                                      BERT ist ein Transformer-Modell, das auf selbstüberwachte Weise auf einem großen Korpus mehrsprachiger Daten vorab trainiert wird.   \n",
       "4                                                                                                                                                                                                                                                                                                                                  Wissen ist Liebe und Licht und Vision.   \n",
       "5                                                                                                                                                                                                                                                                                                                                           Meine Mutter ist Ingenieurin.   \n",
       "6                                                                                                                                                                                                                                                                                                                                    Ist dieser Junge ein guter Künstler?   \n",
       "7                                                                                                                                                                                                                                                                                                        Ich lebe mit meiner Schwester, die auch meine beste Freundin ist   \n",
       "8                                                                                                                                                                                                                                                                                                                                Mein Vater war ein ausgezeichneter Koch.   \n",
       "9                                                                                                                                                                                                                                                                                                                                             Die Mädchen gingen wandern.   \n",
       "10                                                                                                                                                                                                                                                                                                                                        Mögen Sie unsere Mathelehrerin?   \n",
       "11                                                                                                                                                                                                                                                                                                                                 Der Arzt kam heute zu spät zur Arbeit.   \n",
       "12                                                                                                                                                                                                                                                                                                                      Morgen gehen die Studenten zu einer Klassenfahrt.   \n",
       "13                                                                                                                                                                                                                                                                                                                            Diese Krankenschwester arbeitet nicht hart.   \n",
       "14                                                                                                                                                                                                                                                                                                                                          Sportler verdienen viel Geld.   \n",
       "15                                                                                                                                                                                                                                                                                                                                  Ingenieur*innen sind lieb und fleißig   \n",
       "16                                                                                                                                                                                                                                                                                                                    Ingenieure und Ingenieurinnen sind lieb und fleißig   \n",
       "17                                                                                                                                                                                                                                                                                                                                         Lehrende sind lieb und fleißig   \n",
       "18                                                                                                                                                                                                                                                                                                                                     Lehrer:innen sind lieb und fleißig   \n",
       "19                                                                                                                                                                                                                                                                                                                           Lehrerinnen und Lehrer sind lieb und fleißig   \n",
       "20                                                                                                                                                                                                                                                                                                                                           Lehrer sind lieb und fleißig   \n",
       "21                                                                                                                                                                                                                                                                                                                                      Lehrerinnen sind lieb und fleißig   \n",
       "22                                                                                                                                                                                       Wir suchen jemanden für unser Office 365-Team, der die Konzeption, Entwicklung und Integration von Gen AI-Apps und die Integration mithilfe von Microsoft Copilot Studio leitet.   \n",
       "23                                                                            Der ideale Kandidat sollte über solide technische Grundlagen mit Schwerpunkt auf der Entwicklung kundenspezifischer Agenten und Copilot-Integrationen, strategisches Denken, ausgezeichnete Kommunikationsfähigkeiten und die Fähigkeit zur Zusammenarbeit in einem globalen Team verfügen.   \n",
       "24                                                                                                      Im Bereich Technologie nutzen wir Innovationen, um die Verbindungen und Fähigkeiten aufzubauen, die unser Unternehmen voranbringen, und unseren Kunden und Kollegen zu ermöglichen, Märkte neu zu definieren und die Zukunft unserer Gemeinschaften zu gestalten.   \n",
       "25  Dies ist eine Position als Lead Workplace Engineering auf VP-Ebene, die Teil der Jobfamilie ist, die für die Verwaltung und Optimierung der technischen Umgebung und der Endbenutzererfahrung für verschiedene Arbeitsplatztechnologien verantwortlich ist und einen reibungslosen Betrieb sowie die Zufriedenheit der Benutzer im gesamten Unternehmen sicherstellt.   \n",
       "\n",
       "    true_label  predicted_label  neutral_prob  biased_prob  correct  \n",
       "0            0                0      0.999575     0.000425     True  \n",
       "1            0                0      0.999731     0.000269     True  \n",
       "2            0                0      0.999805     0.000195     True  \n",
       "3            0                0      0.688832     0.311168     True  \n",
       "4            0                0      0.999234     0.000766     True  \n",
       "5            0                1      0.441243     0.558757    False  \n",
       "6            0                0      0.622386     0.377614     True  \n",
       "7            0                0      0.998843     0.001157     True  \n",
       "8            0                0      0.907980     0.092020     True  \n",
       "9            0                0      0.998616     0.001384     True  \n",
       "10           1                1      0.091663     0.908337     True  \n",
       "11           1                1      0.000669     0.999331     True  \n",
       "12           1                1      0.000679     0.999321     True  \n",
       "13           1                1      0.001724     0.998276     True  \n",
       "14           1                1      0.001218     0.998782     True  \n",
       "15           0                0      0.954139     0.045861     True  \n",
       "16           0                1      0.000840     0.999160    False  \n",
       "17           0                0      0.997319     0.002681     True  \n",
       "18           0                1      0.031357     0.968643    False  \n",
       "19           0                1      0.000535     0.999465    False  \n",
       "20           1                1      0.000838     0.999162     True  \n",
       "21           1                1      0.000679     0.999321     True  \n",
       "22           0                0      0.996394     0.003607     True  \n",
       "23           1                1      0.000624     0.999376     True  \n",
       "24           1                1      0.000402     0.999598     True  \n",
       "25           1                1      0.001522     0.998478     True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model accuracy on test cases: 84.6%\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nBias detection test results:\")\n",
    "display(results_df)\n",
    "\n",
    "accuracy = results_df[\"correct\"].mean()\n",
    "print(f\"\\nModel accuracy on test cases: {accuracy:.1%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
