{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8487e0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kev\\Documents\\GitHub\\bias-detector-en-de\\thesis-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    set_seed,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import(\n",
    "    accuracy_score, \n",
    "    precision_recall_fscore_support,\n",
    ")\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e222663",
   "metadata": {},
   "source": [
    "# Seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "471a072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "set_seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f6a176",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a751c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b9c6e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>german</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sportsperson is responsible.</td>\n",
       "      <td>Die Sportfreundin ist verantwortlich.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When all is said and done, Mr Pacheco Pereira ...</td>\n",
       "      <td>Schließlich hat Pacheco Pereira eine politisch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mrs President, the Theorin and Smet reports we...</td>\n",
       "      <td>Geehrtes Präsidium! Die Berichte von Theorin u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The contemporaries are diligent.</td>\n",
       "      <td>die Zeitgenoss*innen sind fleißig.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It is clear that many weapons find themselves ...</td>\n",
       "      <td>Natürlich ist klar, dass viele Waffen über Waf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0                   The sportsperson is responsible.   \n",
       "1  When all is said and done, Mr Pacheco Pereira ...   \n",
       "2  Mrs President, the Theorin and Smet reports we...   \n",
       "3                   The contemporaries are diligent.   \n",
       "4  It is clear that many weapons find themselves ...   \n",
       "\n",
       "                                              german  label  \n",
       "0              Die Sportfreundin ist verantwortlich.      1  \n",
       "1  Schließlich hat Pacheco Pereira eine politisch...      1  \n",
       "2  Geehrtes Präsidium! Die Berichte von Theorin u...      1  \n",
       "3                 die Zeitgenoss*innen sind fleißig.      0  \n",
       "4  Natürlich ist klar, dass viele Waffen über Waf...      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f54aa9",
   "metadata": {},
   "source": [
    "# Load pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f279cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU: NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU: None (using CPU)\")\n",
    "# model path\n",
    "model_path = \"bert-base-multilingual-cased\"\n",
    "\n",
    "# model tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# load model with binary classification head\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=2,\n",
    "    id2label={0: \"neutral\", 1: \"biased\"},\n",
    "    label2id={\"neutral\": 0, \"biased\": 1}\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb879bcf",
   "metadata": {},
   "source": [
    "# Set trainable parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b4f305",
   "metadata": {},
   "source": [
    "- \"transfer learning\". we leave the base model parameters frozen, only train a classification head that we add on top\n",
    "- might result in rigid model\n",
    "- unfreeze final four layers, keeping computational cost down but keep flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98bc016c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 14767874\n"
     ]
    }
   ],
   "source": [
    "trainable = [\"encoder.layer.10\", \"encoder.layer.11\", \"pooler\", \"classifier\"]\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = any(layer in name for layer in trainable)\n",
    "\n",
    "# log param counts\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable params: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00540c44",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fd93d9",
   "metadata": {},
   "source": [
    "- PyTorch models need input data in a specific format\n",
    "- BiasDataset class turns each row from df into tokenized input tensors for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d237a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasDataset(Dataset):\n",
    "    # store df and tokenizer\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    # how many samples in dataset\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # runs every time model needs one item from dataset\n",
    "    # grabs english and german sentence, tokenizes them as a pair, applied padding, trunc and max_length, converts into pytorch tensors, returns a dict\n",
    "    def __getitem__(self, idx):\n",
    "        english = self.data.iloc[idx][\"english\"]\n",
    "        german = self.data.iloc[idx][\"german\"]\n",
    "        label = int(self.data.iloc[idx][\"label\"])\n",
    "\n",
    "        encoded = self.tokenizer(\n",
    "            text=english,\n",
    "            text_pair=german,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=256,\n",
    "            return_tensors=\"pt\",\n",
    "            return_overflowing_tokens=False\n",
    "        )\n",
    "\n",
    "        item = {key: val.squeeze(0) for key, val in encoded.items()}\n",
    "        item[\"labels\"] = torch.tensor(label)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bec775",
   "metadata": {},
   "source": [
    "- tokenizer gives tensors with a first size of 1 (a batch)\n",
    "- squeeze(0) removes that first size, making single samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc28df7",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e171490",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(\n",
    "    df, \n",
    "    test_size=0.2, \n",
    "    stratify=df[\"label\"], \n",
    "    random_state=seed\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, \n",
    "    test_size=0.5, \n",
    "    stratify=temp_df[\"label\"], \n",
    "    random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d06d805",
   "metadata": {},
   "source": [
    "## Create Dataset Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f80e26d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BiasDataset(train_df, tokenizer)  \n",
    "val_dataset = BiasDataset(val_df, tokenizer)    \n",
    "test_dataset = BiasDataset(test_df, tokenizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28148ce4",
   "metadata": {},
   "source": [
    "# Define evaluation metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c893c9f",
   "metadata": {},
   "source": [
    "- **`evaluate` function** runs the model on test data to check performance.\n",
    "\n",
    "- `model.eval()`  \n",
    "  - Sets the model to evaluation mode (no training or dropout).\n",
    "\n",
    "- Initialize empty lists:  \n",
    "  - `all_labels` to save true labels.  \n",
    "  - `all_preds` to save predicted labels.\n",
    "\n",
    "- Loop through batches in `dataloader`:  \n",
    "  - Move inputs and labels to device (CPU/GPU).  \n",
    "  - Get model outputs (logits).  \n",
    "  - Select predicted class with highest score (`argmax`).  \n",
    "  - Add true labels and predictions to lists.\n",
    "\n",
    "- After the loop:  \n",
    "  - Calculate **accuracy**: percentage of correct predictions.  \n",
    "  - Calculate **precision**: correct biased predictions / all biased predictions made.  \n",
    "  - Calculate **recall**: correct biased predictions / all actual biased samples.  \n",
    "  - Calculate **f1-score**: balance between precision and recall.\n",
    "\n",
    "- Return all four metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e6231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=1)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d441df9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20be9511",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20dd9a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 2e-5\n",
    "batch_size = 16\n",
    "num_epochs = 8\n",
    "\n",
    "output_dir=\"./model_output\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    seed = seed,\n",
    "    output_dir=output_dir,       \n",
    "    num_train_epochs=num_epochs,   \n",
    "    per_device_train_batch_size=batch_size, \n",
    "    per_device_eval_batch_size=batch_size,   \n",
    "    learning_rate=lr,             \n",
    "    warmup_ratio=0.1,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",       \n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"f1\",  \n",
    "    greater_is_better=True   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c91741",
   "metadata": {},
   "source": [
    "## Run trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d406a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,  \n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d80fcdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2480' max='2480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2480/2480 07:57, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.568600</td>\n",
       "      <td>0.420953</td>\n",
       "      <td>0.762903</td>\n",
       "      <td>0.673846</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.748718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.279547</td>\n",
       "      <td>0.862903</td>\n",
       "      <td>0.910798</td>\n",
       "      <td>0.746154</td>\n",
       "      <td>0.820296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.281800</td>\n",
       "      <td>0.165748</td>\n",
       "      <td>0.924194</td>\n",
       "      <td>0.911197</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.909441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.211600</td>\n",
       "      <td>0.158923</td>\n",
       "      <td>0.938710</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.928302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.181700</td>\n",
       "      <td>0.162077</td>\n",
       "      <td>0.948387</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.939623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>0.151156</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.936090</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.946768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.134400</td>\n",
       "      <td>0.157414</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.943396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.153930</td>\n",
       "      <td>0.953226</td>\n",
       "      <td>0.935849</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.944762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Saving model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model_output\\\\tokenizer_config.json',\n",
       " './model_output\\\\special_tokens_map.json',\n",
       " './model_output\\\\vocab.txt',\n",
       " './model_output\\\\added_tokens.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "\n",
    "try:\n",
    "    train_results = trainer.train()\n",
    "except Exception as e:\n",
    "    print(\"Training failed:\", e)\n",
    "    raise\n",
    "\n",
    "print(\"Training complete. Saving model...\")\n",
    "\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e5e28c",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b7253a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.947\n",
      "Test F1: 0.89\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating model...\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_results = trainer.evaluate(eval_dataset=val_dataset)\n",
    "print(\"Validation F1:\", round(val_results[\"eval_f1\"], 3))\n",
    "\n",
    "# Evaluate on test set\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "print(\"Test F1:\", round(test_results[\"eval_f1\"], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d97164",
   "metadata": {},
   "source": [
    "# Test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "099f1b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = output_dir\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89c62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bias Detection Test Cases:\n",
      "                                                                                                                                                                English                                                                                                                                                                                                                                                 German  True Label  Predicted Label  Neutral Prob  Biased Prob  Correct\n",
      "                                                                                                                                                      The nurse is kind                                                                                                                                                                                                                    Die Krankenschwester ist freundlich           1                1      0.045843     0.954157     True\n",
      "                                                                                                                                    The students don't know what to eat                                                                                                                                                                                                    Die Studierenden wissen nicht, was sie essen sollen           0                0      0.998491     0.001509     True\n",
      "                                                                                                                                                   The doctor is strong                                                                                                                                                                                                                                     Der Arzt ist stark           1                1      0.003868     0.996132     True\n",
      "                                                                                                                                         Today the weather is beautiful                                                                                                                                                                                                                             Heute ist das Wetter schön           0                0      0.999295     0.000705     True\n",
      "                                                                                                                                                   The woman is a coder                                                                                                                                                                                                                      Die Frau ist eine Programmiererin           0                1      0.060344     0.939656    False\n",
      "                                                                                                                                     The teachers are not working today                                                                                                                                                                                                                     Die Lehrenden arbeiten heute nicht           0                0      0.998427     0.001573     True\n",
      "                                                                                                                                     The advisors are not working today                                                                                                                                                                                                                 Die Berater*innen arbeiten heute nicht           0                1      0.169991     0.830010    False\n",
      "                                                                                                                                                 The teachers are smart                                                                                                                                                                                                                                 Die Lehrer sind schlau           1                1      0.001044     0.998956     True\n",
      "                                                                                                                                                              I am fine                                                                                                                                                                                                                                        Mir geht es gut           0                0      0.999048     0.000952     True\n",
      "                                                                                                                                              I am helping the engineer                                                                                                                                                                                                                              Ich helfe der Ingenieurin           1                0      0.836343     0.163657    False\n",
      "                                                                                                                                               I am helping the cleaner                                                                                                                                                                                                                          Ich helfe der Reinigungskraft           0                0      0.998422     0.001578     True\n",
      "                                                                                                                                             Is this boy a good artist?                                                                                                                                                                                                                   Ist dieser Junge ein guter Künstler?           0                0      0.959389     0.040611     True\n",
      "Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Die Softwareentwickler von Google entwickeln Technologien der nächsten Generation, die die Art und Weise verändern, wie Milliarden von Benutzern Verbindungen herstellen, Informationen erkunden und mit Informationen und untereinander interagieren.           1                1      0.104758     0.895242     True\n",
      "\n",
      "Model Accuracy on Test Sentences: 76.9%\n"
     ]
    }
   ],
   "source": [
    "# Define test cases (English, German) with expected bias labels\n",
    "test_cases = [\n",
    "    (\"The nurse is kind\", \"Die Krankenschwester ist freundlich\", 1),  \n",
    "    (\"The students don't know what to eat\", \"Die Studierenden wissen nicht, was sie essen sollen\", 0),       \n",
    "    (\"The doctor is strong\", \"Der Arzt ist stark\", 1),               \n",
    "    (\"Today the weather is beautiful\", \"Heute ist das Wetter schön\", 0), \n",
    "    (\"The woman is a coder\", \"Die Frau ist eine Programmiererin\", 0), \n",
    "    (\"The teachers are not working today\", \"Die Lehrenden arbeiten heute nicht\", 0), \n",
    "    (\"The advisors are not working today\", \"Die Berater*innen arbeiten heute nicht\", 0), \n",
    "    (\"The teachers are smart\", \"Die Lehrer sind schlau\", 1), \n",
    "    (\"I am fine\", \"Mir geht es gut\",0),\n",
    "    (\"I am helping the engineer\", \"Ich helfe der Ingenieurin\",1),\n",
    "    (\"I am helping the cleaner\", \"Ich helfe der Reinigungskraft\",0),\n",
    "    (\"Is this boy a good artist?\", \"Ist dieser Junge ein guter Künstler?\",0),\n",
    "    (\"Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another.\",\"Googles Software-Ingenieure entwickeln die Technologien der nächsten Generation, die ändern, wie Milliarden von Benutzern verbinden, erkunden, und interagieren mit Informationen und einander.\",1)\n",
    "]\n",
    "\n",
    "# Prepare results table\n",
    "results = []\n",
    "\n",
    "# Run predictions\n",
    "for eng, de, true_label in test_cases:\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        eng, de,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        pred_label = torch.argmax(outputs.logits).item()\n",
    "        prob = torch.softmax(outputs.logits, dim=1)[0].cpu().numpy()\n",
    "    \n",
    "    results.append({\n",
    "        \"English\": eng,\n",
    "        \"German\": de,\n",
    "        \"True Label\": true_label,\n",
    "        \"Predicted Label\": pred_label,\n",
    "        \"Neutral Prob\": prob[0],\n",
    "        \"Biased Prob\": prob[1],\n",
    "        \"Correct\": true_label == pred_label\n",
    "    })\n",
    "\n",
    "# Display as formatted table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nBias Detection Test Cases:\")\n",
    "print(results_df.to_string(index=False))  # This prints the whole table cleanly\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = results_df[\"Correct\"].mean()\n",
    "print(f\"\\nModel Accuracy on Test Sentences: {accuracy:.1%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
