{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab0b7990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khali/Documents/GitHub/bias-detector-en-de-1/thesis-env-3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    get_scheduler,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929e611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/mgente_transformed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc2635",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2678737701.py, line 21)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mreturn_tensors=\"pt\"\u001b[39m\n                   ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "class BiasDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=128):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        english = self.data.iloc[idx][\"english\"]\n",
    "        german = self.data.iloc[idx][\"german\"]\n",
    "        label = int(self.data.iloc[idx][\"label\"])\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            english,\n",
    "            german,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "            return_overflowing_tokens=False\n",
    "        )\n",
    "\n",
    "        item = {key: val.squeeze(0) for key, val in inputs.items()}\n",
    "        item[\"labels\"] = torch.tensor(label)\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198d4f1a",
   "metadata": {},
   "source": [
    "- combines english and german sentences into a single string for BERT model\n",
    "- tokenize with padding truncation and max_length\n",
    "- return a dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80f9256",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\", num_labels=2\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc579a6",
   "metadata": {},
   "source": [
    "- uses GPU if available, else falls back to CPU\n",
    "- loads mBERT\n",
    "- specifies binary classification\n",
    "- model.todevice if training happens on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f0dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable = [\"encoder.layer.10\", \"encoder.layer.11\", \"pooler\", \"classifier\"]\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = any(layer in name for layer in trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaaef31",
   "metadata": {},
   "source": [
    "BERT has 12 layers. If you unfreeze all of them, the model will update every weight during training. This:\n",
    "- Takes longer\n",
    "- Requires more GPU memory\n",
    "- Can overwrite useful knowledge from pretraining\n",
    "\n",
    "By freezing most layers and only training the top layers (e.g., layer.10, layer.11, pooler, classifier), you:\n",
    "- Keep general language knowledge\n",
    "- Only train the parts that matter most for gender bias detection\n",
    "\n",
    "- training last two transformer layers (10, 11)\n",
    "- pooler for CLS embedding\n",
    "- classification head\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863574d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=10)\n",
    "train_dataset = BiasDataset(train_df, tokenizer)\n",
    "val_dataset = BiasDataset(val_df, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1240c0eb",
   "metadata": {},
   "source": [
    "- drop last true in case dataset is not divisible by batch_size \n",
    "- not causing issues with layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaa55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 4\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "num_training_steps = len(train_loader) * num_epochs\n",
    "num_warmup_steps = int(0.1 * num_training_steps)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85f3219",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aacbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    avg_train_loss = total_loss / num_batches\n",
    "    train_acc = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Epoch {epoch+1}: Avg Train Loss = {avg_train_loss:.4f} | Train Acc = {train_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6046c8c",
   "metadata": {},
   "source": [
    "## Validation + Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e1483",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "val_loss = 0\n",
    "val_batches = 0\n",
    "val_preds = []\n",
    "val_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        val_loss += outputs.loss.item()\n",
    "        val_batches += 1\n",
    "\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        val_preds.extend(preds.cpu().numpy())\n",
    "        val_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "avg_val_loss = val_loss / val_batches\n",
    "val_acc = accuracy_score(val_labels, val_preds)\n",
    "print(f\"Epoch {epoch+1}: Avg Val Loss = {avg_val_loss:.4f} | Val Acc = {val_acc:.4f}\")\n",
    "\n",
    "# Save best model\n",
    "if avg_val_loss < best_val_loss:\n",
    "    best_val_loss = avg_val_loss\n",
    "    model.save_pretrained(\"./model_output\")\n",
    "    tokenizer.save_pretrained(\"./model_output\")\n",
    "    print(\"âœ… Saved best model.\")\n",
    "\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8492818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./model_output\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867e5da6",
   "metadata": {},
   "source": [
    "- loads saved model weights \n",
    "- loads tokenizer\n",
    "- saves model to cpu or gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7999581",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = BiasDataset(val_df, tokenizer)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd273cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\")\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e22c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, f1 = evaluate_model(model, val_loader)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23f38cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bias(english, german, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Predict if the English-German pair is gender biased.\n",
    "    Returns: label ('Biased' or 'Neutral') and confidence score.\n",
    "    \"\"\"\n",
    "    text_pair = english + \" [SEP] \" + german\n",
    "    inputs = tokenizer(\n",
    "        text_pair,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128,\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=1)\n",
    "        pred = torch.argmax(probs).item()\n",
    "        confidence = probs[0][pred].item()\n",
    "\n",
    "    if pred == 1 and confidence >= threshold:\n",
    "        return \"Biased\", confidence\n",
    "    else:\n",
    "        return \"Neutral\", confidence\n",
    "\n",
    "\n",
    "# Example with multiple sentences per input text\n",
    "long_english_text = (\n",
    "    \"The nurse is kind and helpful. \"\n",
    "    \"The doctor is very experienced.\"\n",
    ")\n",
    "long_german_text = (\n",
    "    \"Die Krankenschwester ist freundlich und hilfsbereit. \"\n",
    "    \"Der Arzt ist sehr erfahren.\"\n",
    ")\n",
    "\n",
    "def simple_sent_tokenize(text):\n",
    "    # Split on dot, question mark, exclamation mark followed by space or end of string\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    return [s for s in sentences if s]\n",
    "\n",
    "english_sentences = simple_sent_tokenize(long_english_text)\n",
    "german_sentences = simple_sent_tokenize(long_german_text)\n",
    "\n",
    "print(\"Checking long text sentence by sentence:\\n\")\n",
    "for en_sent, de_sent in zip(english_sentences, german_sentences):\n",
    "    label, conf = predict_bias(en_sent, de_sent)\n",
    "    print(f\"EN: {en_sent}\")\n",
    "    print(f\"DE: {de_sent}\")\n",
    "    print(f\"Prediction: {label} (Confidence: {conf:.2f})\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# Original simple test examples\n",
    "examples = [\n",
    "    (\"The nurse is kind\", \"Die Krankenschwester ist freundlich\"),\n",
    "    (\"The nurse is kind\", \"Die Pflegekraft ist freundlich\"),\n",
    "    (\"The doctor is strong\", \"Der Arzt ist stark\"),\n",
    "]\n",
    "\n",
    "print(\"\\nSimple example tests:\\n\")\n",
    "for en, de in examples:\n",
    "    label, conf = predict_bias(en, de)\n",
    "    print(f\"EN: {en}\")\n",
    "    print(f\"DE: {de}\")\n",
    "    print(f\"Prediction: {label} (Confidence: {conf:.2f})\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
